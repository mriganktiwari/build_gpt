{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ecc6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475b58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = open('input.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6300da71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(''.join(shakespeare))))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63bb908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e157714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(vocab)}\n",
    "itos = {i:ch for ch,i in stoi.items()}\n",
    "\n",
    "encode = lambda text: [stoi[ch] for ch in text]\n",
    "decode = lambda idx: ''.join([itos[i] for i in idx])\n",
    "\n",
    "decode(encode('Hello there')) # test encode-decode functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec99fe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(shakespeare))\n",
    "encoded_text = encode(shakespeare)\n",
    "print(len(encoded_text))\n",
    "\n",
    "n = int(len(encoded_text) * 0.9)\n",
    "train_data = encoded_text[:n]\n",
    "val_data = encoded_text[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd1467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724d27e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 47, 56, 57, 58, 1, 15, 47, 58]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed37fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] --> 47\n",
      "[18, 47] --> 56\n",
      "[18, 47, 56] --> 57\n",
      "[18, 47, 56, 57] --> 58\n",
      "[18, 47, 56, 57, 58] --> 1\n",
      "[18, 47, 56, 57, 58, 1] --> 15\n",
      "[18, 47, 56, 57, 58, 1, 15] --> 47\n",
      "[18, 47, 56, 57, 58, 1, 15, 47] --> 58\n"
     ]
    }
   ],
   "source": [
    "# look at how inputs - output pairs look like with a given block_size\n",
    "\n",
    "x = train_data[:block_size + 1]\n",
    "for i in range(1, block_size+1):\n",
    "    inp = x[:i]\n",
    "    output = x[i]\n",
    "    print(f'{inp} --> {output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4bb6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "# making a batch of data\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(train_data) - block_size, (batch_size,))\n",
    "\n",
    "    x = torch.tensor([train_data[i : i + block_size] for i in ix])\n",
    "    y = torch.tensor([train_data[i+1 : i + 1 + block_size] for i in ix])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202601f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16,  1, 21, 21, 10,  0, 25, 63],\n",
      "        [50, 47, 54, 58,  1, 50, 47, 49],\n",
      "        [43,  1, 61, 46, 47, 41, 46,  1],\n",
      "        [59, 42,  1, 40, 47, 56, 42, 57]])\n",
      "tensor([[ 1, 21, 21, 10,  0, 25, 63,  1],\n",
      "        [47, 54, 58,  1, 50, 47, 49, 43],\n",
      "        [ 1, 61, 46, 47, 41, 46,  1, 63],\n",
      "        [42,  1, 40, 47, 56, 42, 57,  6]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "\n",
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73472322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16]) --> 1\n",
      "tensor([16,  1]) --> 21\n",
      "tensor([16,  1, 21]) --> 21\n",
      "tensor([16,  1, 21, 21]) --> 10\n",
      "tensor([16,  1, 21, 21, 10]) --> 0\n",
      "tensor([16,  1, 21, 21, 10,  0]) --> 25\n",
      "tensor([16,  1, 21, 21, 10,  0, 25]) --> 63\n",
      "tensor([16,  1, 21, 21, 10,  0, 25, 63]) --> 1\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        inp = xb[b, : t+1]\n",
    "        out = yb[b, t]\n",
    "        print(f'{inp} --> {out}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4e090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.ones(2,4,8)[:,-1:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a45436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_encoding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, targets = None):\n",
    "        # x shape       - (b, t)\n",
    "        # targets shape - (b, t)\n",
    "        logits = self.token_encoding_table(x) # (b, t, vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # B,T,C = logits.shape\n",
    "            loss = F.cross_entropy(logits.transpose(-1,-2), targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (b, t)\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) # (b, t, vocab_size)\n",
    "            logits = logits[:, -1, :] # (b, vocab_size)\n",
    "            probs = F.softmax(logits, dim=-1) # (b, vocab_size)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (b, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (b, t+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5b0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = BigramLM(vocab_size)\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "# logits, loss = bigram_model(xb, yb)\n",
    "# logits.shape, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b24fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AmYBaDstkNBPPuYGI$3yXgka.\n",
      "LXuJKcVU.zmlDdsV?!fgNnfpKojBlaZXuGw:crFdlqgjUQ3KM3GALSiOcKZTRv SX$$.GBKZYs\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(bigram_model.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e76359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6075bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5684943199157715\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "batch_size = 32\n",
    "for _ in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = bigram_model(xb, yb)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e2a4dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F yore, ws oosit ges the, owhowinou he\n",
      "\n",
      "Whe Fimasicismam  hyond l y IENII ar Cllered o, PUSomy\n",
      "\n",
      "\n",
      "I d s, t w illes.\n",
      "Yow sxeaghag at ithesthend pan s, ue, horele dw\n",
      "TOXmacurngomen ain d r-wndsar irtheithon aks cokn.\n",
      "NCHimatote Bumandsthaceiofe laterelee.\n",
      "Mat T:\n",
      "ifaseng aY paroois, ts?\n",
      "PPey indditay ldv nga$MIAnther dith th hanto me manore o madyoner-b.\n",
      "Thich pr hontit Cly o-cave nd whitomest d g d IN han:\n",
      "\n",
      "NVFr stend th, t hit ovedo worinst hechop, m.\n",
      "Bozes! mur he depy vare cesand CKI tl ustrm, I\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(bigram_model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f55da",
   "metadata": {},
   "source": [
    "## Tricks to calculate interactions between tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d1265",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d383a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3352, -0.3542],\n",
       "        [ 1.1348, -2.2493],\n",
       "        [-0.1779, -0.7811],\n",
       "        [-2.7670, -2.7058],\n",
       "        [ 0.3049,  0.5375],\n",
       "        [ 0.4849, -1.5841],\n",
       "        [ 0.7020,  1.2656],\n",
       "        [ 0.2472,  0.6762]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C = 4,8,2\n",
    "x = torch.randn((B,T,C))\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5394e0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3352, -0.3542],\n",
       "        [ 0.3998, -1.3018],\n",
       "        [ 0.2072, -1.1282],\n",
       "        [-0.5363, -1.5226],\n",
       "        [-0.3681, -1.1106],\n",
       "        [-0.2259, -1.1895],\n",
       "        [-0.0933, -0.8388],\n",
       "        [-0.0508, -0.6494]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_context = x[b, :t+1] # (t,c)\n",
    "        xbow[b,t] = torch.mean(x_context, dim=0)\n",
    "\n",
    "xbow[0] # avg of all previous time steps including current step 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123a2e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doing it efficiently: version 2\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / torch.sum(wei, dim=-1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e17d641d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3352, -0.3542],\n",
       "        [ 0.3998, -1.3018],\n",
       "        [ 0.2072, -1.1282],\n",
       "        [-0.5363, -1.5226],\n",
       "        [-0.3681, -1.1106],\n",
       "        [-0.2259, -1.1895],\n",
       "        [-0.0933, -0.8388],\n",
       "        [-0.0508, -0.6494]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2 = wei @ x # (t,t) @ (b,t,c) --> (b,t,c)\n",
    "xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "401f3d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5539522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using softmax to aggregate: version 3\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei = wei.masked_fill_(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "747308f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f7f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (b, t, head_size)\n",
    "q = query(x) # (b, t, head_size)\n",
    "wei = q @ k.transpose(-1, -2) # (b, t, head_size) @ (b, head_size, t) --> (b, t, t)\n",
    "wei = wei.masked_fill_(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "v = value(x) # (b, t, head_size)\n",
    "\n",
    "out = wei @ v # (b, t, t) @ (b, t, head_size) --> (b, t, head_size)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a69ee65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "nn.LayerNorm(\n",
      "    normalized_shape: Union[int, list[int], torch.Size],\n",
      "    eps: float = \u001b[32m1e-05\u001b[39m,\n",
      "    elementwise_affine: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    bias: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    device=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dtype=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Applies Layer Normalization over a mini-batch of inputs.\n",
      "\n",
      "This layer implements the operation as described in\n",
      "the paper `Layer Normalization <https://arxiv.org/abs/1607.06450>`__\n",
      "\n",
      ".. math::\n",
      "    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
      "\n",
      "The mean and standard-deviation are calculated over the last `D` dimensions, where `D`\n",
      "is the dimension of :attr:`normalized_shape`. For example, if :attr:`normalized_shape`\n",
      "is ``(3, 5)`` (a 2-dimensional shape), the mean and standard-deviation are computed over\n",
      "the last 2 dimensions of the input (i.e. ``input.mean((-2, -1))``).\n",
      ":math:`\\gamma` and :math:`\\beta` are learnable affine transform parameters of\n",
      ":attr:`normalized_shape` if :attr:`elementwise_affine` is ``True``.\n",
      "The variance is calculated via the biased estimator, equivalent to\n",
      "`torch.var(input, unbiased=False)`.\n",
      "\n",
      ".. note::\n",
      "    Unlike Batch Normalization and Instance Normalization, which applies\n",
      "    scalar scale and bias for each entire channel/plane with the\n",
      "    :attr:`affine` option, Layer Normalization applies per-element scale and\n",
      "    bias with :attr:`elementwise_affine`.\n",
      "\n",
      "This layer uses statistics computed from input data in both training and\n",
      "evaluation modes.\n",
      "\n",
      "Args:\n",
      "    normalized_shape (int or list or torch.Size): input shape from an expected input\n",
      "        of size\n",
      "\n",
      "        .. math::\n",
      "            [* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n",
      "                \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n",
      "\n",
      "        If a single integer is used, it is treated as a singleton list, and this module will\n",
      "        normalize over the last dimension which is expected to be of that specific size.\n",
      "    eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
      "    elementwise_affine: a boolean value that when set to ``True``, this module\n",
      "        has learnable per-element affine parameters initialized to ones (for weights)\n",
      "        and zeros (for biases). Default: ``True``.\n",
      "    bias: If set to ``False``, the layer will not learn an additive bias (only relevant if\n",
      "        :attr:`elementwise_affine` is ``True``). Default: ``True``.\n",
      "\n",
      "Attributes:\n",
      "    weight: the learnable weights of the module of shape\n",
      "        :math:`\\text{normalized\\_shape}` when :attr:`elementwise_affine` is set to ``True``.\n",
      "        The values are initialized to 1.\n",
      "    bias:   the learnable bias of the module of shape\n",
      "            :math:`\\text{normalized\\_shape}` when :attr:`elementwise_affine` is set to ``True``.\n",
      "            The values are initialized to 0.\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(N, *)`\n",
      "    - Output: :math:`(N, *)` (same shape as input)\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # NLP Example\n",
      "    >>> batch, sentence_length, embedding_dim = 20, 5, 10\n",
      "    >>> embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
      "    >>> layer_norm = nn.LayerNorm(embedding_dim)\n",
      "    >>> # Activate module\n",
      "    >>> layer_norm(embedding)\n",
      "    >>>\n",
      "    >>> # Image Example\n",
      "    >>> N, C, H, W = 20, 5, 10, 10\n",
      "    >>> input = torch.randn(N, C, H, W)\n",
      "    >>> # Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
      "    >>> # as shown in the image below\n",
      "    >>> layer_norm = nn.LayerNorm([C, H, W])\n",
      "    >>> output = layer_norm(input)\n",
      "\n",
      ".. image:: ../_static/img/nn/layer_norm.jpg\n",
      "    :scale: 50 %\n",
      "\u001b[31mInit docstring:\u001b[39m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[31mFile:\u001b[39m           ~/miniforge3/envs/torch/lib/python3.13/site-packages/torch/nn/modules/normalization.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     LayerNorm"
     ]
    }
   ],
   "source": [
    "nn.LayerNorm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45cf26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
