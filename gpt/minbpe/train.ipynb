{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d10c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic import BasicTokenizer\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844cdac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('tests/taylorswift.txt', 'r', encoding='utf-8').read()\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34611a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (101, 32) into a new token 256\n",
      "merge 1/256: (101, 32) -> 256 (b'e ') had 2981 occurences\n",
      "merging (44, 32) into a new token 257\n",
      "merge 2/256: (44, 32) -> 257 (b', ') had 2961 occurences\n",
      "merging (100, 32) into a new token 258\n",
      "merge 3/256: (100, 32) -> 258 (b'd ') had 2617 occurences\n",
      "merging (46, 32) into a new token 259\n",
      "merge 4/256: (46, 32) -> 259 (b'. ') had 2560 occurences\n",
      "merging (114, 32) into a new token 260\n",
      "merge 5/256: (114, 32) -> 260 (b'r ') had 2428 occurences\n",
      "merging (50, 48) into a new token 261\n",
      "merge 6/256: (50, 48) -> 261 (b'20') had 2365 occurences\n",
      "merging (115, 32) into a new token 262\n",
      "merge 7/256: (115, 32) -> 262 (b's ') had 2053 occurences\n",
      "merging (105, 110) into a new token 263\n",
      "merge 8/256: (105, 110) -> 263 (b'in') had 2006 occurences\n",
      "merging (111, 110) into a new token 264\n",
      "merge 9/256: (111, 110) -> 264 (b'on') had 1815 occurences\n",
      "merging (114, 105) into a new token 265\n",
      "merge 10/256: (114, 105) -> 265 (b'ri') had 1805 occurences\n",
      "merging (116, 32) into a new token 266\n",
      "merge 11/256: (116, 32) -> 266 (b't ') had 1802 occurences\n",
      "merging (116, 104) into a new token 267\n",
      "merge 12/256: (116, 104) -> 267 (b'th') had 1737 occurences\n",
      "merging (101, 258) into a new token 268\n",
      "merge 13/256: (101, 258) -> 268 (b'ed ') had 1736 occurences\n",
      "merging (257, 261) into a new token 269\n",
      "merge 14/256: (257, 261) -> 269 (b', 20') had 1705 occurences\n",
      "merging (97, 110) into a new token 270\n",
      "merge 15/256: (97, 110) -> 270 (b'an') had 1487 occurences\n",
      "merging (97, 114) into a new token 271\n",
      "merge 16/256: (97, 114) -> 271 (b'ar') had 1360 occurences\n",
      "merging (101, 260) into a new token 272\n",
      "merge 17/256: (101, 260) -> 272 (b'er ') had 1356 occurences\n",
      "merging (121, 32) into a new token 273\n",
      "merge 18/256: (121, 32) -> 273 (b'y ') had 1248 occurences\n",
      "merging (97, 108) into a new token 274\n",
      "merge 19/256: (97, 108) -> 274 (b'al') had 1164 occurences\n",
      "merging (267, 256) into a new token 275\n",
      "merge 20/256: (267, 256) -> 275 (b'the ') had 1142 occurences\n",
      "merging (118, 268) into a new token 276\n",
      "merge 21/256: (118, 268) -> 276 (b'ved ') had 1104 occurences\n",
      "merging (119, 105) into a new token 277\n",
      "merge 22/256: (119, 105) -> 277 (b'wi') had 1049 occurences\n",
      "merging (101, 114) into a new token 278\n",
      "merge 23/256: (101, 114) -> 278 (b'er') had 897 occurences\n",
      "merging (264, 32) into a new token 279\n",
      "merge 24/256: (264, 32) -> 279 (b'on ') had 880 occurences\n",
      "merging (277, 102) into a new token 280\n",
      "merge 25/256: (277, 102) -> 280 (b'wif') had 871 occurences\n",
      "merging (82, 101) into a new token 281\n",
      "merge 26/256: (82, 101) -> 281 (b'Re') had 870 occurences\n",
      "merging (83, 280) into a new token 282\n",
      "merge 27/256: (83, 280) -> 282 (b'Swif') had 867 occurences\n",
      "merging (111, 260) into a new token 283\n",
      "merge 28/256: (111, 260) -> 283 (b'or ') had 859 occurences\n",
      "merging (99, 104) into a new token 284\n",
      "merge 29/256: (99, 104) -> 284 (b'ch') had 816 occurences\n",
      "merging (269, 49) into a new token 285\n",
      "merge 30/256: (269, 49) -> 285 (b', 201') had 811 occurences\n",
      "merging (111, 109) into a new token 286\n",
      "merge 31/256: (111, 109) -> 286 (b'om') had 789 occurences\n",
      "merging (98, 272) into a new token 287\n",
      "merge 32/256: (98, 272) -> 287 (b'ber ') had 752 occurences\n",
      "merging (32, 275) into a new token 288\n",
      "merge 33/256: (32, 275) -> 288 (b' the ') had 748 occurences\n",
      "merging (97, 121) into a new token 289\n",
      "merge 34/256: (97, 121) -> 289 (b'ay') had 744 occurences\n",
      "merging (101, 110) into a new token 290\n",
      "merge 35/256: (101, 110) -> 290 (b'en') had 740 occurences\n",
      "merging (111, 114) into a new token 291\n",
      "merge 36/256: (111, 114) -> 291 (b'or') had 737 occurences\n",
      "merging (274, 32) into a new token 292\n",
      "merge 37/256: (274, 32) -> 292 (b'al ') had 705 occurences\n",
      "merging (101, 109) into a new token 293\n",
      "merge 38/256: (101, 109) -> 293 (b'em') had 703 occurences\n",
      "merging (46, 10) into a new token 294\n",
      "merge 39/256: (46, 10) -> 294 (b'.\\n') had 685 occurences\n",
      "merging (265, 101) into a new token 295\n",
      "merge 40/256: (265, 101) -> 295 (b'rie') had 685 occurences\n",
      "merging (263, 103) into a new token 296\n",
      "merge 41/256: (263, 103) -> 296 (b'ing') had 684 occurences\n",
      "merging (269, 50) into a new token 297\n",
      "merge 42/256: (269, 50) -> 297 (b', 202') had 673 occurences\n",
      "merging (116, 105) into a new token 298\n",
      "merge 43/256: (116, 105) -> 298 (b'ti') had 666 occurences\n",
      "merging (289, 108) into a new token 299\n",
      "merge 44/256: (289, 108) -> 299 (b'ayl') had 654 occurences\n",
      "merging (34, 259) into a new token 300\n",
      "merge 45/256: (34, 259) -> 300 (b'\". ') had 651 occurences\n",
      "merging (108, 108) into a new token 301\n",
      "merge 46/256: (108, 108) -> 301 (b'll') had 649 occurences\n",
      "merging (84, 299) into a new token 302\n",
      "merge 47/256: (84, 299) -> 302 (b'Tayl') had 647 occurences\n",
      "merging (116, 295) into a new token 303\n",
      "merge 48/256: (116, 295) -> 303 (b'trie') had 644 occurences\n",
      "merging (294, 32) into a new token 304\n",
      "merge 49/256: (294, 32) -> 304 (b'.\\n ') had 643 occurences\n",
      "merging (116, 111) into a new token 305\n",
      "merge 50/256: (116, 111) -> 305 (b'to') had 642 occurences\n",
      "merging (259, 281) into a new token 306\n",
      "merge 51/256: (259, 281) -> 306 (b'. Re') had 640 occurences\n",
      "merging (306, 303) into a new token 307\n",
      "merge 52/256: (306, 303) -> 307 (b'. Retrie') had 639 occurences\n",
      "merging (307, 276) into a new token 308\n",
      "merge 53/256: (307, 276) -> 308 (b'. Retrieved ') had 639 occurences\n",
      "merging (302, 283) into a new token 309\n",
      "merge 54/256: (302, 283) -> 309 (b'Taylor ') had 611 occurences\n",
      "merging (101, 115) into a new token 310\n",
      "merge 55/256: (101, 115) -> 310 (b'es') had 606 occurences\n",
      "merging (309, 282) into a new token 311\n",
      "merge 56/256: (309, 282) -> 311 (b'Taylor Swif') had 598 occurences\n",
      "merging (117, 115) into a new token 312\n",
      "merge 57/256: (117, 115) -> 312 (b'us') had 561 occurences\n",
      "merging (114, 286) into a new token 313\n",
      "merge 58/256: (114, 286) -> 313 (b'rom') had 532 occurences\n",
      "merging (293, 287) into a new token 314\n",
      "merge 59/256: (293, 287) -> 314 (b'ember ') had 528 occurences\n",
      "merging (41, 259) into a new token 315\n",
      "merge 60/256: (41, 259) -> 315 (b'). ') had 524 occurences\n",
      "merging (65, 114) into a new token 316\n",
      "merge 61/256: (65, 114) -> 316 (b'Ar') had 509 occurences\n",
      "merging (102, 313) into a new token 317\n",
      "merge 62/256: (102, 313) -> 317 (b'from') had 503 occurences\n",
      "merging (315, 34) into a new token 318\n",
      "merge 63/256: (315, 34) -> 318 (b'). \"') had 499 occurences\n",
      "merging (270, 258) into a new token 319\n",
      "merge 64/256: (270, 258) -> 319 (b'and ') had 498 occurences\n",
      "merging (114, 101) into a new token 320\n",
      "merge 65/256: (114, 101) -> 320 (b're') had 495 occurences\n",
      "merging (111, 117) into a new token 321\n",
      "merge 66/256: (111, 117) -> 321 (b'ou') had 487 occurences\n",
      "merging (111, 265) into a new token 322\n",
      "merge 67/256: (111, 265) -> 322 (b'ori') had 469 occurences\n",
      "merging (111, 102) into a new token 323\n",
      "merge 68/256: (111, 102) -> 323 (b'of') had 466 occurences\n",
      "merging (103, 263) into a new token 324\n",
      "merge 69/256: (103, 263) -> 324 (b'gin') had 465 occurences\n",
      "merging (296, 32) into a new token 325\n",
      "merge 70/256: (296, 32) -> 325 (b'ing ') had 464 occurences\n",
      "merging (284, 105) into a new token 326\n",
      "merge 71/256: (284, 105) -> 326 (b'chi') had 458 occurences\n",
      "merging (93, 32) into a new token 327\n",
      "merge 72/256: (93, 32) -> 327 (b'] ') had 458 occurences\n",
      "merging (324, 292) into a new token 328\n",
      "merge 73/256: (324, 292) -> 328 (b'ginal ') had 453 occurences\n",
      "merging (317, 288) into a new token 329\n",
      "merge 74/256: (317, 288) -> 329 (b'from the ') had 447 occurences\n",
      "merging (322, 328) into a new token 330\n",
      "merge 75/256: (322, 328) -> 330 (b'original ') had 446 occurences\n",
      "merging (104, 256) into a new token 331\n",
      "merge 76/256: (104, 256) -> 331 (b'he ') had 440 occurences\n",
      "merging (316, 326) into a new token 332\n",
      "merge 77/256: (316, 326) -> 332 (b'Archi') had 440 occurences\n",
      "merging (332, 276) into a new token 333\n",
      "merge 78/256: (332, 276) -> 333 (b'Archived ') had 440 occurences\n",
      "merging (329, 330) into a new token 334\n",
      "merge 79/256: (329, 330) -> 334 (b'from the original ') had 440 occurences\n",
      "merging (333, 334) into a new token 335\n",
      "merge 80/256: (333, 334) -> 335 (b'Archived from the original ') had 439 occurences\n",
      "merging (335, 279) into a new token 336\n",
      "merge 81/256: (335, 279) -> 336 (b'Archived from the original on ') had 438 occurences\n",
      "merging (259, 336) into a new token 337\n",
      "merge 82/256: (259, 336) -> 337 (b'. Archived from the original on ') had 433 occurences\n",
      "merging (97, 32) into a new token 338\n",
      "merge 83/256: (97, 32) -> 338 (b'a ') had 420 occurences\n",
      "merging (115, 116) into a new token 339\n",
      "merge 84/256: (115, 116) -> 339 (b'st') had 409 occurences\n",
      "merging (105, 99) into a new token 340\n",
      "merge 85/256: (105, 99) -> 340 (b'ic') had 406 occurences\n",
      "merging (46, 91) into a new token 341\n",
      "merge 86/256: (46, 91) -> 341 (b'.[') had 381 occurences\n",
      "merging (101, 99) into a new token 342\n",
      "merge 87/256: (101, 99) -> 342 (b'ec') had 374 occurences\n",
      "merging (105, 301) into a new token 343\n",
      "merge 88/256: (105, 301) -> 343 (b'ill') had 367 occurences\n",
      "merging (39, 262) into a new token 344\n",
      "merge 89/256: (39, 262) -> 344 (b\"'s \") had 367 occurences\n",
      "merging (311, 266) into a new token 345\n",
      "merge 90/256: (311, 266) -> 345 (b'Taylor Swift ') had 352 occurences\n",
      "merging (111, 118) into a new token 346\n",
      "merge 91/256: (111, 118) -> 346 (b'ov') had 343 occurences\n",
      "merging (97, 116) into a new token 347\n",
      "merge 92/256: (97, 116) -> 347 (b'at') had 334 occurences\n",
      "merging (97, 262) into a new token 348\n",
      "merge 93/256: (97, 262) -> 348 (b'as ') had 315 occurences\n",
      "merging (101, 262) into a new token 349\n",
      "merge 94/256: (101, 262) -> 349 (b'es ') had 309 occurences\n",
      "merging (74, 117) into a new token 350\n",
      "merge 95/256: (74, 117) -> 350 (b'Ju') had 307 occurences\n",
      "merging (323, 32) into a new token 351\n",
      "merge 96/256: (323, 32) -> 351 (b'of ') had 306 occurences\n",
      "merging (305, 32) into a new token 352\n",
      "merge 97/256: (305, 32) -> 352 (b'to ') had 284 occurences\n",
      "merging (117, 109) into a new token 353\n",
      "merge 98/256: (117, 109) -> 353 (b'um') had 281 occurences\n",
      "merging (84, 331) into a new token 354\n",
      "merge 99/256: (84, 331) -> 354 (b'The ') had 277 occurences\n",
      "merging (271, 100) into a new token 355\n",
      "merge 100/256: (271, 100) -> 355 (b'ard') had 277 occurences\n",
      "merging (263, 32) into a new token 356\n",
      "merge 101/256: (263, 32) -> 356 (b'in ') had 276 occurences\n",
      "merging (270, 32) into a new token 357\n",
      "merge 102/256: (270, 32) -> 357 (b'an ') had 276 occurences\n",
      "merging (101, 108) into a new token 358\n",
      "merge 103/256: (101, 108) -> 358 (b'el') had 275 occurences\n",
      "merging (297, 51) into a new token 359\n",
      "merge 104/256: (297, 51) -> 359 (b', 2023') had 271 occurences\n",
      "merging (271, 273) into a new token 360\n",
      "merge 105/256: (271, 273) -> 360 (b'ary ') had 259 occurences\n",
      "merging (267, 32) into a new token 361\n",
      "merge 106/256: (267, 32) -> 361 (b'th ') had 258 occurences\n",
      "merging (97, 109) into a new token 362\n",
      "merge 107/256: (97, 109) -> 362 (b'am') had 257 occurences\n",
      "merging (108, 273) into a new token 363\n",
      "merge 108/256: (108, 273) -> 363 (b'ly ') had 250 occurences\n",
      "merging (111, 112) into a new token 364\n",
      "merge 109/256: (111, 112) -> 364 (b'op') had 249 occurences\n",
      "merging (311, 116) into a new token 365\n",
      "merge 110/256: (311, 116) -> 365 (b'Taylor Swift') had 246 occurences\n",
      "merging (116, 114) into a new token 366\n",
      "merge 111/256: (116, 114) -> 366 (b'tr') had 243 occurences\n",
      "merging (105, 115) into a new token 367\n",
      "merge 112/256: (105, 115) -> 367 (b'is') had 234 occurences\n",
      "merging (104, 272) into a new token 368\n",
      "merge 113/256: (104, 272) -> 368 (b'her ') had 232 occurences\n",
      "merging (111, 32) into a new token 369\n",
      "merge 114/256: (111, 32) -> 369 (b'o ') had 225 occurences\n",
      "merging (117, 360) into a new token 370\n",
      "merge 115/256: (117, 360) -> 370 (b'uary ') had 225 occurences\n",
      "merging (78, 346) into a new token 371\n",
      "merge 116/256: (78, 346) -> 371 (b'Nov') had 222 occurences\n",
      "merging (312, 340) into a new token 372\n",
      "merge 117/256: (312, 340) -> 372 (b'usic') had 221 occurences\n",
      "merging (371, 314) into a new token 373\n",
      "merge 118/256: (371, 314) -> 373 (b'November ') had 221 occurences\n",
      "merging (101, 119) into a new token 374\n",
      "merge 119/256: (101, 119) -> 374 (b'ew') had 219 occurences\n",
      "merging (97, 266) into a new token 375\n",
      "merge 120/256: (97, 266) -> 375 (b'at ') had 219 occurences\n",
      "merging (108, 32) into a new token 376\n",
      "merge 121/256: (108, 32) -> 376 (b'l ') had 218 occurences\n",
      "merging (58, 32) into a new token 377\n",
      "merge 122/256: (58, 32) -> 377 (b': ') had 213 occurences\n",
      "merging (98, 111) into a new token 378\n",
      "merge 123/256: (98, 111) -> 378 (b'bo') had 210 occurences\n",
      "merging (282, 266) into a new token 379\n",
      "merge 124/256: (282, 266) -> 379 (b'Swift ') had 208 occurences\n",
      "merging (68, 342) into a new token 380\n",
      "merge 125/256: (68, 342) -> 380 (b'Dec') had 207 occurences\n",
      "merging (105, 116) into a new token 381\n",
      "merge 126/256: (105, 116) -> 381 (b'it') had 206 occurences\n",
      "merging (105, 103) into a new token 382\n",
      "merge 127/256: (105, 103) -> 382 (b'ig') had 205 occurences\n",
      "merging (66, 343) into a new token 383\n",
      "merge 128/256: (66, 343) -> 383 (b'Bill') had 205 occurences\n",
      "merging (49, 48) into a new token 384\n",
      "merge 129/256: (49, 48) -> 384 (b'10') had 204 occurences\n",
      "merging (97, 115) into a new token 385\n",
      "merge 130/256: (97, 115) -> 385 (b'as') had 203 occurences\n",
      "merging (264, 103) into a new token 386\n",
      "merge 131/256: (264, 103) -> 386 (b'ong') had 202 occurences\n",
      "merging (79, 99) into a new token 387\n",
      "merge 132/256: (79, 99) -> 387 (b'Oc') had 200 occurences\n",
      "merging (97, 298) into a new token 388\n",
      "merge 133/256: (97, 298) -> 388 (b'ati') had 199 occurences\n",
      "merging (83, 116) into a new token 389\n",
      "merge 134/256: (83, 116) -> 389 (b'St') had 198 occurences\n",
      "merging (387, 305) into a new token 390\n",
      "merge 135/256: (387, 305) -> 390 (b'Octo') had 198 occurences\n",
      "merging (390, 287) into a new token 391\n",
      "merge 136/256: (390, 287) -> 391 (b'October ') had 198 occurences\n",
      "merging (97, 99) into a new token 392\n",
      "merge 137/256: (97, 99) -> 392 (b'ac') had 197 occurences\n",
      "merging (111, 119) into a new token 393\n",
      "merge 138/256: (111, 119) -> 393 (b'ow') had 196 occurences\n",
      "merging (380, 314) into a new token 394\n",
      "merge 139/256: (380, 314) -> 394 (b'December ') had 194 occurences\n",
      "merging (383, 378) into a new token 395\n",
      "merge 140/256: (383, 378) -> 395 (b'Billbo') had 191 occurences\n",
      "merging (97, 100) into a new token 396\n",
      "merge 141/256: (97, 100) -> 396 (b'ad') had 190 occurences\n",
      "merging (108, 101) into a new token 397\n",
      "merge 142/256: (108, 101) -> 397 (b'le') had 190 occurences\n",
      "merging (117, 114) into a new token 398\n",
      "merge 143/256: (117, 114) -> 398 (b'ur') had 188 occurences\n",
      "merging (102, 283) into a new token 399\n",
      "merge 144/256: (102, 283) -> 399 (b'for ') had 188 occurences\n",
      "merging (32, 40) into a new token 400\n",
      "merge 145/256: (32, 40) -> 400 (b' (') had 187 occurences\n",
      "merging (297, 50) into a new token 401\n",
      "merge 146/256: (297, 50) -> 401 (b', 2022') had 187 occurences\n",
      "merging (117, 103) into a new token 402\n",
      "merge 147/256: (117, 103) -> 402 (b'ug') had 185 occurences\n",
      "merging (284, 32) into a new token 403\n",
      "merge 148/256: (284, 32) -> 403 (b'ch ') had 184 occurences\n",
      "merging (115, 266) into a new token 404\n",
      "merge 149/256: (115, 266) -> 404 (b'st ') had 181 occurences\n",
      "merging (321, 110) into a new token 405\n",
      "merge 150/256: (321, 110) -> 405 (b'oun') had 176 occurences\n",
      "merging (98, 353) into a new token 406\n",
      "merge 151/256: (98, 353) -> 406 (b'bum') had 172 occurences\n",
      "merging (111, 108) into a new token 407\n",
      "merge 152/256: (111, 108) -> 407 (b'ol') had 171 occurences\n",
      "merging (312, 266) into a new token 408\n",
      "merge 153/256: (312, 266) -> 408 (b'ust ') had 171 occurences\n",
      "merging (101, 98) into a new token 409\n",
      "merge 154/256: (101, 98) -> 409 (b'eb') had 170 occurences\n",
      "merging (77, 97) into a new token 410\n",
      "merge 155/256: (77, 97) -> 410 (b'Ma') had 170 occurences\n",
      "merging (350, 363) into a new token 411\n",
      "merge 156/256: (350, 363) -> 411 (b'July ') had 170 occurences\n",
      "merging (318, 345) into a new token 412\n",
      "merge 157/256: (318, 345) -> 412 (b'). \"Taylor Swift ') had 169 occurences\n",
      "merging (107, 32) into a new token 413\n",
      "merge 158/256: (107, 32) -> 413 (b'k ') had 165 occurences\n",
      "merging (278, 115) into a new token 414\n",
      "merge 159/256: (278, 115) -> 414 (b'ers') had 164 occurences\n",
      "merging (93, 91) into a new token 415\n",
      "merge 160/256: (93, 91) -> 415 (b'][') had 164 occurences\n",
      "merging (65, 402) into a new token 416\n",
      "merge 161/256: (65, 402) -> 416 (b'Aug') had 164 occurences\n",
      "merging (416, 408) into a new token 417\n",
      "merge 162/256: (416, 408) -> 417 (b'August ') had 163 occurences\n",
      "merging (105, 100) into a new token 418\n",
      "merge 163/256: (105, 100) -> 418 (b'id') had 161 occurences\n",
      "merging (297, 49) into a new token 419\n",
      "merge 164/256: (297, 49) -> 419 (b', 2021') had 160 occurences\n",
      "merging (109, 101) into a new token 420\n",
      "merge 165/256: (109, 101) -> 420 (b'me') had 159 occurences\n",
      "merging (101, 112) into a new token 421\n",
      "merge 166/256: (101, 112) -> 421 (b'ep') had 156 occurences\n",
      "merging (261, 49) into a new token 422\n",
      "merge 167/256: (261, 49) -> 422 (b'201') had 149 occurences\n",
      "merging (50, 51) into a new token 423\n",
      "merge 168/256: (50, 51) -> 423 (b'23') had 145 occurences\n",
      "merging (285, 50) into a new token 424\n",
      "merge 169/256: (285, 50) -> 424 (b', 2012') had 144 occurences\n",
      "merging (101, 271) into a new token 425\n",
      "merge 170/256: (101, 271) -> 425 (b'ear') had 140 occurences\n",
      "merging (269, 261) into a new token 426\n",
      "merge 171/256: (269, 261) -> 426 (b', 2020') had 140 occurences\n",
      "merging (73, 110) into a new token 427\n",
      "merge 172/256: (73, 110) -> 427 (b'In') had 139 occurences\n",
      "merging (102, 105) into a new token 428\n",
      "merge 173/256: (102, 105) -> 428 (b'fi') had 139 occurences\n",
      "merging (110, 256) into a new token 429\n",
      "merge 174/256: (110, 256) -> 429 (b'ne ') had 139 occurences\n",
      "merging (395, 355) into a new token 430\n",
      "merge 175/256: (395, 355) -> 430 (b'Billboard') had 136 occurences\n",
      "merging (265, 116) into a new token 431\n",
      "merge 176/256: (265, 116) -> 431 (b'rit') had 134 occurences\n",
      "merging (104, 105) into a new token 432\n",
      "merge 177/256: (104, 105) -> 432 (b'hi') had 133 occurences\n",
      "merging (372, 32) into a new token 433\n",
      "merge 178/256: (372, 32) -> 433 (b'usic ') had 133 occurences\n",
      "merging (304, 34) into a new token 434\n",
      "merge 179/256: (304, 34) -> 434 (b'.\\n \"') had 133 occurences\n",
      "merging (78, 374) into a new token 435\n",
      "merge 180/256: (78, 374) -> 435 (b'New') had 131 occurences\n",
      "merging (100, 105) into a new token 436\n",
      "merge 181/256: (100, 105) -> 436 (b'di') had 130 occurences\n",
      "merging (65, 112) into a new token 437\n",
      "merge 182/256: (65, 112) -> 437 (b'Ap') had 130 occurences\n",
      "merging (285, 57) into a new token 438\n",
      "merge 183/256: (285, 57) -> 438 (b', 2019') had 129 occurences\n",
      "merging (114, 111) into a new token 439\n",
      "merge 184/256: (114, 111) -> 439 (b'ro') had 128 occurences\n",
      "merging (39, 32) into a new token 440\n",
      "merge 185/256: (39, 32) -> 440 (b\"' \") had 128 occurences\n",
      "merging (115, 257) into a new token 441\n",
      "merge 186/256: (115, 257) -> 441 (b's, ') had 127 occurences\n",
      "merging (350, 429) into a new token 442\n",
      "merge 187/256: (350, 429) -> 442 (b'June ') had 127 occurences\n",
      "merging (323, 288) into a new token 443\n",
      "merge 188/256: (323, 288) -> 443 (b'of the ') had 126 occurences\n",
      "merging (99, 291) into a new token 444\n",
      "merge 189/256: (99, 291) -> 444 (b'cor') had 126 occurences\n",
      "merging (50, 49) into a new token 445\n",
      "merge 190/256: (50, 49) -> 445 (b'21') had 126 occurences\n",
      "merging (49, 57) into a new token 446\n",
      "merge 191/256: (49, 57) -> 446 (b'19') had 124 occurences\n",
      "merging (105, 109) into a new token 447\n",
      "merge 192/256: (105, 109) -> 447 (b'im') had 123 occurences\n",
      "merging (290, 32) into a new token 448\n",
      "merge 193/256: (290, 32) -> 448 (b'en ') had 123 occurences\n",
      "merging (409, 114) into a new token 449\n",
      "merge 194/256: (409, 114) -> 449 (b'ebr') had 122 occurences\n",
      "merging (290, 116) into a new token 450\n",
      "merge 195/256: (290, 116) -> 450 (b'ent') had 121 occurences\n",
      "merging (111, 301) into a new token 451\n",
      "merge 196/256: (111, 301) -> 451 (b'oll') had 121 occurences\n",
      "merging (77, 271) into a new token 452\n",
      "merge 197/256: (77, 271) -> 452 (b'Mar') had 120 occurences\n",
      "merging (265, 99) into a new token 453\n",
      "merge 198/256: (265, 99) -> 453 (b'ric') had 120 occurences\n",
      "merging (277, 361) into a new token 454\n",
      "merge 199/256: (277, 361) -> 454 (b'with ') had 120 occurences\n",
      "merging (44, 91) into a new token 455\n",
      "merge 200/256: (44, 91) -> 455 (b',[') had 118 occurences\n",
      "merging (70, 449) into a new token 456\n",
      "merge 201/256: (70, 449) -> 456 (b'Febr') had 118 occurences\n",
      "merging (456, 370) into a new token 457\n",
      "merge 202/256: (456, 370) -> 457 (b'February ') had 118 occurences\n",
      "merging (365, 344) into a new token 458\n",
      "merge 203/256: (365, 344) -> 458 (b\"Taylor Swift's \") had 118 occurences\n",
      "merging (300, 430) into a new token 459\n",
      "merge 204/256: (300, 430) -> 459 (b'\". Billboard') had 118 occurences\n",
      "merging (101, 97) into a new token 460\n",
      "merge 205/256: (101, 97) -> 460 (b'ea') had 116 occurences\n",
      "merging (285, 54) into a new token 461\n",
      "merge 206/256: (285, 54) -> 461 (b', 2016') had 116 occurences\n",
      "merging (421, 116) into a new token 462\n",
      "merge 207/256: (421, 116) -> 462 (b'ept') had 115 occurences\n",
      "merging (410, 273) into a new token 463\n",
      "merge 208/256: (410, 273) -> 463 (b'May ') had 115 occurences\n",
      "merging (285, 53) into a new token 464\n",
      "merge 209/256: (285, 53) -> 464 (b', 2015') had 115 occurences\n",
      "merging (437, 265) into a new token 465\n",
      "merge 210/256: (437, 265) -> 465 (b'Apri') had 115 occurences\n",
      "merging (465, 376) into a new token 466\n",
      "merge 211/256: (465, 376) -> 466 (b'April ') had 115 occurences\n",
      "merging (108, 256) into a new token 467\n",
      "merge 212/256: (108, 256) -> 467 (b'le ') had 113 occurences\n",
      "merging (65, 119) into a new token 468\n",
      "merge 213/256: (65, 119) -> 468 (b'Aw') had 112 occurences\n",
      "merging (388, 264) into a new token 469\n",
      "merge 214/256: (388, 264) -> 469 (b'ation') had 112 occurences\n",
      "merging (83, 462) into a new token 470\n",
      "merge 215/256: (83, 462) -> 470 (b'Sept') had 112 occurences\n",
      "merging (470, 314) into a new token 471\n",
      "merge 216/256: (470, 314) -> 471 (b'September ') had 112 occurences\n",
      "merging (114, 97) into a new token 472\n",
      "merge 217/256: (114, 97) -> 472 (b'ra') had 111 occurences\n",
      "merging (274, 406) into a new token 473\n",
      "merge 218/256: (274, 406) -> 473 (b'album') had 111 occurences\n",
      "merging (67, 104) into a new token 474\n",
      "merge 219/256: (67, 104) -> 474 (b'Ch') had 110 occurences\n",
      "merging (118, 256) into a new token 475\n",
      "merge 220/256: (118, 256) -> 475 (b've ') had 109 occurences\n",
      "merging (310, 266) into a new token 476\n",
      "merge 221/256: (310, 266) -> 476 (b'est ') had 108 occurences\n",
      "merging (74, 270) into a new token 477\n",
      "merge 222/256: (74, 270) -> 477 (b'Jan') had 108 occurences\n",
      "merging (50, 50) into a new token 478\n",
      "merge 223/256: (50, 50) -> 478 (b'22') had 107 occurences\n",
      "merging (477, 370) into a new token 479\n",
      "merge 224/256: (477, 370) -> 479 (b'January ') had 107 occurences\n",
      "merging (405, 366) into a new token 480\n",
      "merge 225/256: (405, 366) -> 480 (b'ountr') had 106 occurences\n",
      "merging (382, 104) into a new token 481\n",
      "merge 226/256: (382, 104) -> 481 (b'igh') had 106 occurences\n",
      "merging (300, 354) into a new token 482\n",
      "merge 227/256: (300, 354) -> 482 (b'\". The ') had 106 occurences\n",
      "merging (359, 304) into a new token 483\n",
      "merge 228/256: (359, 304) -> 483 (b', 2023.\\n ') had 106 occurences\n",
      "merging (49, 51) into a new token 484\n",
      "merge 229/256: (49, 51) -> 484 (b'13') had 105 occurences\n",
      "merging (65, 108) into a new token 485\n",
      "merge 230/256: (65, 108) -> 485 (b'Al') had 105 occurences\n",
      "merging (101, 116) into a new token 486\n",
      "merge 231/256: (101, 116) -> 486 (b'et') had 105 occurences\n",
      "merging (310, 115) into a new token 487\n",
      "merge 232/256: (310, 115) -> 487 (b'ess') had 103 occurences\n",
      "merging (452, 403) into a new token 488\n",
      "merge 233/256: (452, 403) -> 488 (b'March ') had 103 occurences\n",
      "merging (117, 116) into a new token 489\n",
      "merge 234/256: (117, 116) -> 489 (b'ut') had 102 occurences\n",
      "merging (119, 431) into a new token 490\n",
      "merge 235/256: (119, 431) -> 490 (b'writ') had 101 occurences\n",
      "merging (108, 111) into a new token 491\n",
      "merge 236/256: (108, 111) -> 491 (b'lo') had 99 occurences\n",
      "merging (115, 386) into a new token 492\n",
      "merge 237/256: (115, 386) -> 492 (b'song') had 97 occurences\n",
      "merging (226, 128) into a new token 493\n",
      "merge 238/256: (226, 128) -> 493 (b'\\xe2\\x80') had 97 occurences\n",
      "merging (271, 258) into a new token 494\n",
      "merge 239/256: (271, 258) -> 494 (b'ard ') had 97 occurences\n",
      "merging (48, 32) into a new token 495\n",
      "merge 240/256: (48, 32) -> 495 (b'0 ') had 97 occurences\n",
      "merging (117, 108) into a new token 496\n",
      "merge 241/256: (117, 108) -> 496 (b'ul') had 96 occurences\n",
      "merging (50, 52) into a new token 497\n",
      "merge 242/256: (50, 52) -> 497 (b'24') had 95 occurences\n",
      "merging (105, 262) into a new token 498\n",
      "merge 243/256: (105, 262) -> 498 (b'is ') had 94 occurences\n",
      "merging (298, 99) into a new token 499\n",
      "merge 244/256: (298, 99) -> 499 (b'tic') had 93 occurences\n",
      "merging (97, 103) into a new token 500\n",
      "merge 245/256: (97, 103) -> 500 (b'ag') had 93 occurences\n",
      "merging (34, 32) into a new token 501\n",
      "merge 246/256: (34, 32) -> 501 (b'\" ') had 93 occurences\n",
      "merging (65, 110) into a new token 502\n",
      "merge 247/256: (65, 110) -> 502 (b'An') had 93 occurences\n",
      "merging (49, 56) into a new token 503\n",
      "merge 248/256: (49, 56) -> 503 (b'18') had 93 occurences\n",
      "merging (102, 291) into a new token 504\n",
      "merge 249/256: (102, 291) -> 504 (b'for') had 90 occurences\n",
      "merging (480, 273) into a new token 505\n",
      "merge 250/256: (480, 273) -> 505 (b'ountry ') had 89 occurences\n",
      "merging (65, 420) into a new token 506\n",
      "merge 251/256: (65, 420) -> 506 (b'Ame') had 88 occurences\n",
      "merging (506, 453) into a new token 507\n",
      "merge 252/256: (506, 453) -> 507 (b'Americ') had 88 occurences\n",
      "merging (32, 84) into a new token 508\n",
      "merge 253/256: (32, 84) -> 508 (b' T') had 88 occurences\n",
      "merging (115, 296) into a new token 509\n",
      "merge 254/256: (115, 296) -> 509 (b'sing') had 87 occurences\n",
      "merging (119, 348) into a new token 510\n",
      "merge 255/256: (119, 348) -> 510 (b'was ') had 86 occurences\n",
      "merging (49, 50) into a new token 511\n",
      "merge 256/256: (49, 50) -> 511 (b'12') had 86 occurences\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.train(text, 512, verbose=True)\n",
    "prefix = os.path.join('models', 'basic')\n",
    "tokenizer.save(prefix)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1287f55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 5.96 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training took {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230f18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(101, 32): 256, (44, 32): 257, (100, 32): 258, (46, 32): 259, (114, 32): 260, (50, 48): 261, (115, 32): 262, (105, 110): 263, (111, 110): 264, (114, 105): 265, (116, 32): 266, (116, 104): 267, (101, 258): 268, (257, 261): 269, (97, 110): 270, (97, 114): 271, (101, 260): 272, (121, 32): 273, (97, 108): 274, (267, 256): 275, (118, 268): 276, (119, 105): 277, (101, 114): 278, (264, 32): 279, (277, 102): 280, (82, 101): 281, (83, 280): 282, (111, 260): 283, (99, 104): 284, (269, 49): 285, (111, 109): 286, (98, 272): 287, (32, 275): 288, (97, 121): 289, (101, 110): 290, (111, 114): 291, (274, 32): 292, (101, 109): 293, (46, 10): 294, (265, 101): 295, (263, 103): 296, (269, 50): 297, (116, 105): 298, (289, 108): 299, (34, 259): 300, (108, 108): 301, (84, 299): 302, (116, 295): 303, (294, 32): 304, (116, 111): 305, (259, 281): 306, (306, 303): 307, (307, 276): 308, (302, 283): 309, (101, 115): 310, (309, 282): 311, (117, 115): 312, (114, 286): 313, (293, 287): 314, (41, 259): 315, (65, 114): 316, (102, 313): 317, (315, 34): 318, (270, 258): 319, (114, 101): 320, (111, 117): 321, (111, 265): 322, (111, 102): 323, (103, 263): 324, (296, 32): 325, (284, 105): 326, (93, 32): 327, (324, 292): 328, (317, 288): 329, (322, 328): 330, (104, 256): 331, (316, 326): 332, (332, 276): 333, (329, 330): 334, (333, 334): 335, (335, 279): 336, (259, 336): 337, (97, 32): 338, (115, 116): 339, (105, 99): 340, (46, 91): 341, (101, 99): 342, (105, 301): 343, (39, 262): 344, (311, 266): 345, (111, 118): 346, (97, 116): 347, (97, 262): 348, (101, 262): 349, (74, 117): 350, (323, 32): 351, (305, 32): 352, (117, 109): 353, (84, 331): 354, (271, 100): 355, (263, 32): 356, (270, 32): 357, (101, 108): 358, (297, 51): 359, (271, 273): 360, (267, 32): 361, (97, 109): 362, (108, 273): 363, (111, 112): 364, (311, 116): 365, (116, 114): 366, (105, 115): 367, (104, 272): 368, (111, 32): 369, (117, 360): 370, (78, 346): 371, (312, 340): 372, (371, 314): 373, (101, 119): 374, (97, 266): 375, (108, 32): 376, (58, 32): 377, (98, 111): 378, (282, 266): 379, (68, 342): 380, (105, 116): 381, (105, 103): 382, (66, 343): 383, (49, 48): 384, (97, 115): 385, (264, 103): 386, (79, 99): 387, (97, 298): 388, (83, 116): 389, (387, 305): 390, (390, 287): 391, (97, 99): 392, (111, 119): 393, (380, 314): 394, (383, 378): 395, (97, 100): 396, (108, 101): 397, (117, 114): 398, (102, 283): 399, (32, 40): 400, (297, 50): 401, (117, 103): 402, (284, 32): 403, (115, 266): 404, (321, 110): 405, (98, 353): 406, (111, 108): 407, (312, 266): 408, (101, 98): 409, (77, 97): 410, (350, 363): 411, (318, 345): 412, (107, 32): 413, (278, 115): 414, (93, 91): 415, (65, 402): 416, (416, 408): 417, (105, 100): 418, (297, 49): 419, (109, 101): 420, (101, 112): 421, (261, 49): 422, (50, 51): 423, (285, 50): 424, (101, 271): 425, (269, 261): 426, (73, 110): 427, (102, 105): 428, (110, 256): 429, (395, 355): 430, (265, 116): 431, (104, 105): 432, (372, 32): 433, (304, 34): 434, (78, 374): 435, (100, 105): 436, (65, 112): 437, (285, 57): 438, (114, 111): 439, (39, 32): 440, (115, 257): 441, (350, 429): 442, (323, 288): 443, (99, 291): 444, (50, 49): 445, (49, 57): 446, (105, 109): 447, (290, 32): 448, (409, 114): 449, (290, 116): 450, (111, 301): 451, (77, 271): 452, (265, 99): 453, (277, 361): 454, (44, 91): 455, (70, 449): 456, (456, 370): 457, (365, 344): 458, (300, 430): 459, (101, 97): 460, (285, 54): 461, (421, 116): 462, (410, 273): 463, (285, 53): 464, (437, 265): 465, (465, 376): 466, (108, 256): 467, (65, 119): 468, (388, 264): 469, (83, 462): 470, (470, 314): 471, (114, 97): 472, (274, 406): 473, (67, 104): 474, (118, 256): 475, (310, 266): 476, (74, 270): 477, (50, 50): 478, (477, 370): 479, (405, 366): 480, (382, 104): 481, (300, 354): 482, (359, 304): 483, (49, 51): 484, (65, 108): 485, (101, 116): 486, (310, 115): 487, (452, 403): 488, (117, 116): 489, (119, 431): 490, (108, 111): 491, (115, 386): 492, (226, 128): 493, (271, 258): 494, (48, 32): 495, (117, 108): 496, (50, 52): 497, (105, 262): 498, (298, 99): 499, (97, 103): 500, (34, 32): 501, (65, 110): 502, (49, 56): 503, (102, 291): 504, (480, 273): 505, (65, 420): 506, (506, 453): 507, (32, 84): 508, (115, 296): 509, (119, 348): 510, (49, 50): 511}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4613de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: b'\\x00', 1: b'\\x01', 2: b'\\x02', 3: b'\\x03', 4: b'\\x04', 5: b'\\x05', 6: b'\\x06', 7: b'\\x07', 8: b'\\x08', 9: b'\\t', 10: b'\\n', 11: b'\\x0b', 12: b'\\x0c', 13: b'\\r', 14: b'\\x0e', 15: b'\\x0f', 16: b'\\x10', 17: b'\\x11', 18: b'\\x12', 19: b'\\x13', 20: b'\\x14', 21: b'\\x15', 22: b'\\x16', 23: b'\\x17', 24: b'\\x18', 25: b'\\x19', 26: b'\\x1a', 27: b'\\x1b', 28: b'\\x1c', 29: b'\\x1d', 30: b'\\x1e', 31: b'\\x1f', 32: b' ', 33: b'!', 34: b'\"', 35: b'#', 36: b'$', 37: b'%', 38: b'&', 39: b\"'\", 40: b'(', 41: b')', 42: b'*', 43: b'+', 44: b',', 45: b'-', 46: b'.', 47: b'/', 48: b'0', 49: b'1', 50: b'2', 51: b'3', 52: b'4', 53: b'5', 54: b'6', 55: b'7', 56: b'8', 57: b'9', 58: b':', 59: b';', 60: b'<', 61: b'=', 62: b'>', 63: b'?', 64: b'@', 65: b'A', 66: b'B', 67: b'C', 68: b'D', 69: b'E', 70: b'F', 71: b'G', 72: b'H', 73: b'I', 74: b'J', 75: b'K', 76: b'L', 77: b'M', 78: b'N', 79: b'O', 80: b'P', 81: b'Q', 82: b'R', 83: b'S', 84: b'T', 85: b'U', 86: b'V', 87: b'W', 88: b'X', 89: b'Y', 90: b'Z', 91: b'[', 92: b'\\\\', 93: b']', 94: b'^', 95: b'_', 96: b'`', 97: b'a', 98: b'b', 99: b'c', 100: b'd', 101: b'e', 102: b'f', 103: b'g', 104: b'h', 105: b'i', 106: b'j', 107: b'k', 108: b'l', 109: b'm', 110: b'n', 111: b'o', 112: b'p', 113: b'q', 114: b'r', 115: b's', 116: b't', 117: b'u', 118: b'v', 119: b'w', 120: b'x', 121: b'y', 122: b'z', 123: b'{', 124: b'|', 125: b'}', 126: b'~', 127: b'\\x7f', 128: b'\\x80', 129: b'\\x81', 130: b'\\x82', 131: b'\\x83', 132: b'\\x84', 133: b'\\x85', 134: b'\\x86', 135: b'\\x87', 136: b'\\x88', 137: b'\\x89', 138: b'\\x8a', 139: b'\\x8b', 140: b'\\x8c', 141: b'\\x8d', 142: b'\\x8e', 143: b'\\x8f', 144: b'\\x90', 145: b'\\x91', 146: b'\\x92', 147: b'\\x93', 148: b'\\x94', 149: b'\\x95', 150: b'\\x96', 151: b'\\x97', 152: b'\\x98', 153: b'\\x99', 154: b'\\x9a', 155: b'\\x9b', 156: b'\\x9c', 157: b'\\x9d', 158: b'\\x9e', 159: b'\\x9f', 160: b'\\xa0', 161: b'\\xa1', 162: b'\\xa2', 163: b'\\xa3', 164: b'\\xa4', 165: b'\\xa5', 166: b'\\xa6', 167: b'\\xa7', 168: b'\\xa8', 169: b'\\xa9', 170: b'\\xaa', 171: b'\\xab', 172: b'\\xac', 173: b'\\xad', 174: b'\\xae', 175: b'\\xaf', 176: b'\\xb0', 177: b'\\xb1', 178: b'\\xb2', 179: b'\\xb3', 180: b'\\xb4', 181: b'\\xb5', 182: b'\\xb6', 183: b'\\xb7', 184: b'\\xb8', 185: b'\\xb9', 186: b'\\xba', 187: b'\\xbb', 188: b'\\xbc', 189: b'\\xbd', 190: b'\\xbe', 191: b'\\xbf', 192: b'\\xc0', 193: b'\\xc1', 194: b'\\xc2', 195: b'\\xc3', 196: b'\\xc4', 197: b'\\xc5', 198: b'\\xc6', 199: b'\\xc7', 200: b'\\xc8', 201: b'\\xc9', 202: b'\\xca', 203: b'\\xcb', 204: b'\\xcc', 205: b'\\xcd', 206: b'\\xce', 207: b'\\xcf', 208: b'\\xd0', 209: b'\\xd1', 210: b'\\xd2', 211: b'\\xd3', 212: b'\\xd4', 213: b'\\xd5', 214: b'\\xd6', 215: b'\\xd7', 216: b'\\xd8', 217: b'\\xd9', 218: b'\\xda', 219: b'\\xdb', 220: b'\\xdc', 221: b'\\xdd', 222: b'\\xde', 223: b'\\xdf', 224: b'\\xe0', 225: b'\\xe1', 226: b'\\xe2', 227: b'\\xe3', 228: b'\\xe4', 229: b'\\xe5', 230: b'\\xe6', 231: b'\\xe7', 232: b'\\xe8', 233: b'\\xe9', 234: b'\\xea', 235: b'\\xeb', 236: b'\\xec', 237: b'\\xed', 238: b'\\xee', 239: b'\\xef', 240: b'\\xf0', 241: b'\\xf1', 242: b'\\xf2', 243: b'\\xf3', 244: b'\\xf4', 245: b'\\xf5', 246: b'\\xf6', 247: b'\\xf7', 248: b'\\xf8', 249: b'\\xf9', 250: b'\\xfa', 251: b'\\xfb', 252: b'\\xfc', 253: b'\\xfd', 254: b'\\xfe', 255: b'\\xff', 256: b'e ', 257: b', ', 258: b'd ', 259: b'. ', 260: b'r ', 261: b'20', 262: b's ', 263: b'in', 264: b'on', 265: b'ri', 266: b't ', 267: b'th', 268: b'ed ', 269: b', 20', 270: b'an', 271: b'ar', 272: b'er ', 273: b'y ', 274: b'al', 275: b'the ', 276: b'ved ', 277: b'wi', 278: b'er', 279: b'on ', 280: b'wif', 281: b'Re', 282: b'Swif', 283: b'or ', 284: b'ch', 285: b', 201', 286: b'om', 287: b'ber ', 288: b' the ', 289: b'ay', 290: b'en', 291: b'or', 292: b'al ', 293: b'em', 294: b'.\\n', 295: b'rie', 296: b'ing', 297: b', 202', 298: b'ti', 299: b'ayl', 300: b'\". ', 301: b'll', 302: b'Tayl', 303: b'trie', 304: b'.\\n ', 305: b'to', 306: b'. Re', 307: b'. Retrie', 308: b'. Retrieved ', 309: b'Taylor ', 310: b'es', 311: b'Taylor Swif', 312: b'us', 313: b'rom', 314: b'ember ', 315: b'). ', 316: b'Ar', 317: b'from', 318: b'). \"', 319: b'and ', 320: b're', 321: b'ou', 322: b'ori', 323: b'of', 324: b'gin', 325: b'ing ', 326: b'chi', 327: b'] ', 328: b'ginal ', 329: b'from the ', 330: b'original ', 331: b'he ', 332: b'Archi', 333: b'Archived ', 334: b'from the original ', 335: b'Archived from the original ', 336: b'Archived from the original on ', 337: b'. Archived from the original on ', 338: b'a ', 339: b'st', 340: b'ic', 341: b'.[', 342: b'ec', 343: b'ill', 344: b\"'s \", 345: b'Taylor Swift ', 346: b'ov', 347: b'at', 348: b'as ', 349: b'es ', 350: b'Ju', 351: b'of ', 352: b'to ', 353: b'um', 354: b'The ', 355: b'ard', 356: b'in ', 357: b'an ', 358: b'el', 359: b', 2023', 360: b'ary ', 361: b'th ', 362: b'am', 363: b'ly ', 364: b'op', 365: b'Taylor Swift', 366: b'tr', 367: b'is', 368: b'her ', 369: b'o ', 370: b'uary ', 371: b'Nov', 372: b'usic', 373: b'November ', 374: b'ew', 375: b'at ', 376: b'l ', 377: b': ', 378: b'bo', 379: b'Swift ', 380: b'Dec', 381: b'it', 382: b'ig', 383: b'Bill', 384: b'10', 385: b'as', 386: b'ong', 387: b'Oc', 388: b'ati', 389: b'St', 390: b'Octo', 391: b'October ', 392: b'ac', 393: b'ow', 394: b'December ', 395: b'Billbo', 396: b'ad', 397: b'le', 398: b'ur', 399: b'for ', 400: b' (', 401: b', 2022', 402: b'ug', 403: b'ch ', 404: b'st ', 405: b'oun', 406: b'bum', 407: b'ol', 408: b'ust ', 409: b'eb', 410: b'Ma', 411: b'July ', 412: b'). \"Taylor Swift ', 413: b'k ', 414: b'ers', 415: b'][', 416: b'Aug', 417: b'August ', 418: b'id', 419: b', 2021', 420: b'me', 421: b'ep', 422: b'201', 423: b'23', 424: b', 2012', 425: b'ear', 426: b', 2020', 427: b'In', 428: b'fi', 429: b'ne ', 430: b'Billboard', 431: b'rit', 432: b'hi', 433: b'usic ', 434: b'.\\n \"', 435: b'New', 436: b'di', 437: b'Ap', 438: b', 2019', 439: b'ro', 440: b\"' \", 441: b's, ', 442: b'June ', 443: b'of the ', 444: b'cor', 445: b'21', 446: b'19', 447: b'im', 448: b'en ', 449: b'ebr', 450: b'ent', 451: b'oll', 452: b'Mar', 453: b'ric', 454: b'with ', 455: b',[', 456: b'Febr', 457: b'February ', 458: b\"Taylor Swift's \", 459: b'\". Billboard', 460: b'ea', 461: b', 2016', 462: b'ept', 463: b'May ', 464: b', 2015', 465: b'Apri', 466: b'April ', 467: b'le ', 468: b'Aw', 469: b'ation', 470: b'Sept', 471: b'September ', 472: b'ra', 473: b'album', 474: b'Ch', 475: b've ', 476: b'est ', 477: b'Jan', 478: b'22', 479: b'January ', 480: b'ountr', 481: b'igh', 482: b'\". The ', 483: b', 2023.\\n ', 484: b'13', 485: b'Al', 486: b'et', 487: b'ess', 488: b'March ', 489: b'ut', 490: b'writ', 491: b'lo', 492: b'song', 493: b'\\xe2\\x80', 494: b'ard ', 495: b'0 ', 496: b'ul', 497: b'24', 498: b'is ', 499: b'tic', 500: b'ag', 501: b'\" ', 502: b'An', 503: b'18', 504: b'for', 505: b'ountry ', 506: b'Ame', 507: b'Americ', 508: b' T', 509: b'sing', 510: b'was ', 511: b'12'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cd10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b71bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
