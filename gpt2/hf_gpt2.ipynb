{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fade83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "model = model.to('mps')\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e96002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.439808"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters()) / 10**6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c704f18",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e338b775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 464, 1049,  308, 1381, 1525,  373, 1991,  268,  416]],\n",
       "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"The great gatsby was writen by\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to('mps')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b1cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 464 --> \"The\"\n",
      "Token: 1049 --> \" great\"\n",
      "Token: 308 --> \" g\"\n",
      "Token: 1381 --> \"ats\"\n",
      "Token: 1525 --> \"by\"\n",
      "Token: 373 --> \" was\"\n",
      "Token: 1991 --> \" writ\"\n",
      "Token: 268 --> \"en\"\n",
      "Token: 416 --> \" by\"\n"
     ]
    }
   ],
   "source": [
    "for tok in inputs['input_ids'][0]:\n",
    "    print(f'Token: {tok} --> \"{tokenizer.decode(tok)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cac09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3964f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The great gatsby was writen by the great gatsby, and the great gatsby was writen by the great gatsby.\n",
      "\n",
      "The great gatsby was writen by the great gatsby, and the great gatsby was writen by the\n"
     ]
    }
   ],
   "source": [
    "# output_ids.shape\n",
    "generation = tokenizer.decode(output_ids[0])\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1906587",
   "metadata": {},
   "source": [
    "## Looking at `state_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371ad851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight --> torch.Size([50257, 768])\n",
      "transformer.wpe.weight --> torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.0.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.0.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.0.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.1.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.1.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.1.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.1.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.2.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.2.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.2.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.2.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.3.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.3.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.3.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.3.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.4.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.4.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.4.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.4.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.5.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.5.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.5.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.5.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.6.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.6.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.6.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.6.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.7.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.7.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.7.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.7.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.8.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.8.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.8.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.8.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.9.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.9.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.9.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.9.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.10.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.10.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.10.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.10.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.11.ln_1.weight --> torch.Size([768])\n",
      "transformer.h.11.ln_1.bias --> torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight --> torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias --> torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight --> torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias --> torch.Size([768])\n",
      "transformer.h.11.ln_2.weight --> torch.Size([768])\n",
      "transformer.h.11.ln_2.bias --> torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight --> torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias --> torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight --> torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias --> torch.Size([768])\n",
      "transformer.ln_f.weight --> torch.Size([768])\n",
      "transformer.ln_f.bias --> torch.Size([768])\n",
      "lm_head.weight --> torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "sd = model.state_dict()\n",
    "for k,v in sd.items():\n",
    "    print(f'{k} --> {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0120c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.h.0.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.0.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.1.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.1.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.2.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.2.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.3.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.3.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.4.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.4.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.5.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.5.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.6.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.6.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.7.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.7.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.8.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.8.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.9.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.9.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.10.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.10.attn.masked_bias --> torch.Size([])\n",
      "transformer.h.11.attn.bias --> torch.Size([1, 1, 1024, 1024])\n",
      "transformer.h.11.attn.masked_bias --> torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for name, buf in model.named_buffers():\n",
    "    print(f'{name} --> {buf.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4852e",
   "metadata": {},
   "source": [
    "## Understanding concepts: trial & error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bd6db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "b,t,n_embd,nh = 4,8,32,2\n",
    "attn = torch.randn((b,nh,t,t))\n",
    "\n",
    "tril = torch.tril(torch.ones(t,t))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75191ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0778,  0.7493, -1.5499,  0.9596,  0.8623,  1.4935, -0.4171,  2.5074],\n",
      "        [ 0.4212,  0.0917,  0.8075, -0.2261,  0.4150,  0.5669,  0.5562,  1.5054],\n",
      "        [-0.3372,  0.3031, -2.5702, -0.2523,  0.0713,  0.7166,  0.3191, -0.1069],\n",
      "        [ 0.1994, -3.3223, -2.2039, -1.4927,  0.7381,  0.6496, -1.1768, -1.7605],\n",
      "        [-0.6342, -0.5386,  1.2512, -1.0820, -0.3892,  0.9771, -0.0119, -0.4760],\n",
      "        [-0.3823, -0.6987, -1.0331, -0.1693,  1.2746,  1.4286, -0.4293,  2.3684],\n",
      "        [-0.0249,  0.4048, -1.1959, -0.4532, -0.0941, -0.7197,  0.1757, -0.6452],\n",
      "        [-1.8539, -1.0931, -0.8180,  2.2152,  1.3110, -0.3808, -0.4433,  1.5723]])\n",
      "tensor([[ 0.0167, -0.0424, -0.0515, -0.4647, -0.8529,  1.5306, -0.2215, -1.1013],\n",
      "        [ 1.0849,  0.7927, -0.4453,  0.5311, -1.2426, -0.7290,  0.6556,  0.6728],\n",
      "        [ 0.5365,  0.4651,  0.9445, -0.5449,  0.5725,  0.2194, -0.5900, -0.1532],\n",
      "        [-0.3240,  0.0746, -1.3033, -1.0187,  1.0816, -1.1399,  1.5229,  1.2672],\n",
      "        [-0.4447, -1.0310,  0.3259,  1.2606,  0.6395, -0.5270,  1.5217,  0.3156],\n",
      "        [-0.1187,  0.1898, -1.7028,  0.2347, -0.5496,  1.3012,  0.5167, -1.7138],\n",
      "        [ 0.0439, -0.2344,  0.3273,  1.4227,  0.7644, -0.6338, -1.6199, -0.1450],\n",
      "        [ 0.7034, -0.7059,  0.5520,  0.5414,  1.0143, -1.3008, -0.3582,  0.2969]])\n"
     ]
    }
   ],
   "source": [
    "print(attn[0][0])\n",
    "print(attn[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305fe15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0778,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.4212,  0.0917,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.3372,  0.3031, -2.5702,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.1994, -3.3223, -2.2039, -1.4927,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.6342, -0.5386,  1.2512, -1.0820, -0.3892,    -inf,    -inf,    -inf],\n",
      "        [-0.3823, -0.6987, -1.0331, -0.1693,  1.2746,  1.4286,    -inf,    -inf],\n",
      "        [-0.0249,  0.4048, -1.1959, -0.4532, -0.0941, -0.7197,  0.1757,    -inf],\n",
      "        [-1.8539, -1.0931, -0.8180,  2.2152,  1.3110, -0.3808, -0.4433,  1.5723]])\n",
      "tensor([[ 0.0167,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 1.0849,  0.7927,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.5365,  0.4651,  0.9445,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.3240,  0.0746, -1.3033, -1.0187,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.4447, -1.0310,  0.3259,  1.2606,  0.6395,    -inf,    -inf,    -inf],\n",
      "        [-0.1187,  0.1898, -1.7028,  0.2347, -0.5496,  1.3012,    -inf,    -inf],\n",
      "        [ 0.0439, -0.2344,  0.3273,  1.4227,  0.7644, -0.6338, -1.6199,    -inf],\n",
      "        [ 0.7034, -0.7059,  0.5520,  0.5414,  1.0143, -1.3008, -0.3582,  0.2969]])\n"
     ]
    }
   ],
   "source": [
    "print((attn.masked_fill(tril == 0, float('-inf')))[0][0])\n",
    "print((attn.masked_fill(tril == 0, float('-inf')))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f57886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8]), torch.Size([1, 1, 8, 8]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril1 = torch.tril(torch.ones(t,t))\n",
    "tril2 = torch.tril(torch.ones(t,t)).view(1,1,t,t)\n",
    "tril1.shape, tril2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa99a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "att1 = attn.masked_fill(tril1==0, float('-inf'))\n",
    "att2 = attn.masked_fill(tril2[:,:,]==0, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf8d474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(att1, att2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243669bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0666be2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 7, 0, 5, 5, 2],\n",
      "        [9, 0, 8, 4, 5, 5]])\n",
      "tensor([[2, 7],\n",
      "        [9, 0]])\n",
      "tensor([[0, 5],\n",
      "        [8, 4]])\n",
      "tensor([[5, 2],\n",
      "        [5, 5]])\n"
     ]
    }
   ],
   "source": [
    "emb = 2\n",
    "qkv = torch.randint(0, 10, (emb, 3*emb))\n",
    "# print(qkv.shape)\n",
    "print(qkv)\n",
    "\n",
    "q,k,v = qkv.split(emb, dim=-1)\n",
    "# q.shape, k.shape, v.shape\n",
    "print(q)\n",
    "print(k)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87da7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ecb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50728572",
   "metadata": {},
   "source": [
    "## `state_dict` keys manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99864c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(list(sd.keys()), '\\n')\n",
    "for key in list(sd.keys()):\n",
    "    if key.endswith('.attn.bias'):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd35141",
   "metadata": {},
   "source": [
    "## testing `any` function in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04caf90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"transformer.h.11.ln_2.weight\"\n",
    "text_list = [\"ln_1\", \"ln_3\", \"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f64cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suck\n"
     ]
    }
   ],
   "source": [
    "if any(w in my_string for w in text_list):\n",
    "    print('Fuck')\n",
    "else:\n",
    "    print(\"suck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab911dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b6e2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(\"fuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f30889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
