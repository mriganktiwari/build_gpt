{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53896b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8028a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = open('../gpt/input.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c9c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c018e4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(''.join(shakespeare))))\n",
    "# print(''.join(vocab))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfd0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(vocab)}\n",
    "itos = {i:ch for ch,i in stoi.items()}\n",
    "\n",
    "# encode list of characters to list of integers\n",
    "encode = lambda s: [stoi[ch] for ch in s]\n",
    "# encode('Hello')\n",
    "\n",
    "# decode list of int to list of chars\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "# decode(encode('Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7f309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(shakespeare))\n",
    "len(data) == len(shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8224c572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce7e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]), 'First Citi')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10], shakespeare[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1a8264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57]) tensor([47, 56, 57, 58])\n",
      "--------------------\n",
      "tensor([18]) --> 47\n",
      "tensor([18, 47]) --> 56\n",
      "tensor([18, 47, 56]) --> 57\n",
      "tensor([18, 47, 56, 57]) --> 58\n"
     ]
    }
   ],
   "source": [
    "# prepare inputs n outputs\n",
    "\n",
    "block_size = 4 # time dimension\n",
    "# [18, 47, 56, 57]  --> [58]\n",
    "# [18]              --> [47]\n",
    "# [18, 47]          --> [56]\n",
    "# [18, 47, 56]      --> [57]\n",
    "\n",
    "x, y = data[:block_size], data[1:block_size+1]\n",
    "print(x, y)\n",
    "print('-'*20)\n",
    "for t in range(block_size):\n",
    "    inp = x[:t+1]\n",
    "    out = y[t]\n",
    "    print(f'{inp} --> {out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "216cba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[39, 42, 39, 51],\n",
      "        [56,  1, 57, 50]]) \n",
      " tensor([[42, 39, 51, 10],\n",
      "        [ 1, 57, 50, 39]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "ix = torch.randint(0, len(data), (batch_size,))\n",
    "x = torch.stack([data[i:i+block_size] for i in ix], dim=0)\n",
    "y = torch.stack([data[i+1 : i+1 + block_size] for i in ix], dim=0)\n",
    "print(x, '\\n' ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f11621de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(data)*0.9)\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "ccdee74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[51, 53, 56, 43],\n",
      "        [21, 31, 13, 14],\n",
      "        [53, 59, 56,  1],\n",
      "        [56, 58,  1, 51],\n",
      "        [58, 57,  1, 46],\n",
      "        [44,  1, 14, 53],\n",
      "        [56, 57, 43, 50],\n",
      "        [ 1, 61, 47, 50],\n",
      "        [43,  1, 57, 46],\n",
      "        [52, 53, 47, 52],\n",
      "        [47, 50, 50, 39],\n",
      "        [60, 43,  1, 54],\n",
      "        [21, 57,  1, 57],\n",
      "        [43, 56, 43,  1],\n",
      "        [46, 47, 51,  1],\n",
      "        [57,  1, 58, 46],\n",
      "        [52, 45,  1, 58],\n",
      "        [52,  1, 61, 47],\n",
      "        [ 0, 31, 46, 43],\n",
      "        [39, 47, 52, 58],\n",
      "        [40, 43, 47, 52],\n",
      "        [46, 39, 58,  1],\n",
      "        [12,  5,  0, 13],\n",
      "        [32, 46, 39, 52],\n",
      "        [ 6,  1, 42, 39],\n",
      "        [ 0, 14, 59, 58],\n",
      "        [58,  1, 58, 53],\n",
      "        [52, 41, 43, 12],\n",
      "        [50, 39, 47, 52],\n",
      "        [ 6,  1, 39, 52],\n",
      "        [58, 46, 63,  0],\n",
      "        [10,  0, 13,  1]]) \n",
      " tensor([[53, 56, 43,  1],\n",
      "        [31, 13, 14, 17],\n",
      "        [59, 56,  1, 46],\n",
      "        [58,  1, 51, 63],\n",
      "        [57,  1, 46, 43],\n",
      "        [ 1, 14, 53, 50],\n",
      "        [57, 43, 50, 60],\n",
      "        [61, 47, 50, 50],\n",
      "        [ 1, 57, 46, 53],\n",
      "        [53, 47, 52, 58],\n",
      "        [50, 50, 39, 47],\n",
      "        [43,  1, 54, 53],\n",
      "        [57,  1, 57, 46],\n",
      "        [56, 43,  1, 46],\n",
      "        [47, 51,  1, 46],\n",
      "        [ 1, 58, 46, 43],\n",
      "        [45,  1, 58, 46],\n",
      "        [ 1, 61, 47, 58],\n",
      "        [31, 46, 43, 54],\n",
      "        [47, 52, 58,  1],\n",
      "        [43, 47, 52, 45],\n",
      "        [39, 58,  1, 61],\n",
      "        [ 5,  0, 13, 52],\n",
      "        [46, 39, 52,  1],\n",
      "        [ 1, 42, 39, 57],\n",
      "        [14, 59, 58,  1],\n",
      "        [ 1, 58, 53,  1],\n",
      "        [41, 43, 12,  0],\n",
      "        [39, 47, 52, 43],\n",
      "        [ 1, 39, 52, 42],\n",
      "        [46, 63,  0, 45],\n",
      "        [ 0, 13,  1, 52]])\n",
      "\n",
      "tensor([51]) --> 53\n",
      "tensor([51, 53]) --> 56\n",
      "tensor([51, 53, 56]) --> 43\n",
      "tensor([51, 53, 56, 43]) --> 1\n",
      "tensor([21]) --> 31\n",
      "tensor([21, 31]) --> 13\n",
      "tensor([21, 31, 13]) --> 14\n",
      "tensor([21, 31, 13, 14]) --> 17\n",
      "tensor([53]) --> 59\n",
      "tensor([53, 59]) --> 56\n",
      "tensor([53, 59, 56]) --> 1\n",
      "tensor([53, 59, 56,  1]) --> 46\n",
      "tensor([56]) --> 58\n",
      "tensor([56, 58]) --> 1\n",
      "tensor([56, 58,  1]) --> 51\n",
      "tensor([56, 58,  1, 51]) --> 63\n",
      "tensor([58]) --> 57\n",
      "tensor([58, 57]) --> 1\n",
      "tensor([58, 57,  1]) --> 46\n",
      "tensor([58, 57,  1, 46]) --> 43\n",
      "tensor([44]) --> 1\n",
      "tensor([44,  1]) --> 14\n",
      "tensor([44,  1, 14]) --> 53\n",
      "tensor([44,  1, 14, 53]) --> 50\n",
      "tensor([56]) --> 57\n",
      "tensor([56, 57]) --> 43\n",
      "tensor([56, 57, 43]) --> 50\n",
      "tensor([56, 57, 43, 50]) --> 60\n",
      "tensor([1]) --> 61\n",
      "tensor([ 1, 61]) --> 47\n",
      "tensor([ 1, 61, 47]) --> 50\n",
      "tensor([ 1, 61, 47, 50]) --> 50\n",
      "tensor([43]) --> 1\n",
      "tensor([43,  1]) --> 57\n",
      "tensor([43,  1, 57]) --> 46\n",
      "tensor([43,  1, 57, 46]) --> 53\n",
      "tensor([52]) --> 53\n",
      "tensor([52, 53]) --> 47\n",
      "tensor([52, 53, 47]) --> 52\n",
      "tensor([52, 53, 47, 52]) --> 58\n",
      "tensor([47]) --> 50\n",
      "tensor([47, 50]) --> 50\n",
      "tensor([47, 50, 50]) --> 39\n",
      "tensor([47, 50, 50, 39]) --> 47\n",
      "tensor([60]) --> 43\n",
      "tensor([60, 43]) --> 1\n",
      "tensor([60, 43,  1]) --> 54\n",
      "tensor([60, 43,  1, 54]) --> 53\n",
      "tensor([21]) --> 57\n",
      "tensor([21, 57]) --> 1\n",
      "tensor([21, 57,  1]) --> 57\n",
      "tensor([21, 57,  1, 57]) --> 46\n",
      "tensor([43]) --> 56\n",
      "tensor([43, 56]) --> 43\n",
      "tensor([43, 56, 43]) --> 1\n",
      "tensor([43, 56, 43,  1]) --> 46\n",
      "tensor([46]) --> 47\n",
      "tensor([46, 47]) --> 51\n",
      "tensor([46, 47, 51]) --> 1\n",
      "tensor([46, 47, 51,  1]) --> 46\n",
      "tensor([57]) --> 1\n",
      "tensor([57,  1]) --> 58\n",
      "tensor([57,  1, 58]) --> 46\n",
      "tensor([57,  1, 58, 46]) --> 43\n",
      "tensor([52]) --> 45\n",
      "tensor([52, 45]) --> 1\n",
      "tensor([52, 45,  1]) --> 58\n",
      "tensor([52, 45,  1, 58]) --> 46\n",
      "tensor([52]) --> 1\n",
      "tensor([52,  1]) --> 61\n",
      "tensor([52,  1, 61]) --> 47\n",
      "tensor([52,  1, 61, 47]) --> 58\n",
      "tensor([0]) --> 31\n",
      "tensor([ 0, 31]) --> 46\n",
      "tensor([ 0, 31, 46]) --> 43\n",
      "tensor([ 0, 31, 46, 43]) --> 54\n",
      "tensor([39]) --> 47\n",
      "tensor([39, 47]) --> 52\n",
      "tensor([39, 47, 52]) --> 58\n",
      "tensor([39, 47, 52, 58]) --> 1\n",
      "tensor([40]) --> 43\n",
      "tensor([40, 43]) --> 47\n",
      "tensor([40, 43, 47]) --> 52\n",
      "tensor([40, 43, 47, 52]) --> 45\n",
      "tensor([46]) --> 39\n",
      "tensor([46, 39]) --> 58\n",
      "tensor([46, 39, 58]) --> 1\n",
      "tensor([46, 39, 58,  1]) --> 61\n",
      "tensor([12]) --> 5\n",
      "tensor([12,  5]) --> 0\n",
      "tensor([12,  5,  0]) --> 13\n",
      "tensor([12,  5,  0, 13]) --> 52\n",
      "tensor([32]) --> 46\n",
      "tensor([32, 46]) --> 39\n",
      "tensor([32, 46, 39]) --> 52\n",
      "tensor([32, 46, 39, 52]) --> 1\n",
      "tensor([6]) --> 1\n",
      "tensor([6, 1]) --> 42\n",
      "tensor([ 6,  1, 42]) --> 39\n",
      "tensor([ 6,  1, 42, 39]) --> 57\n",
      "tensor([0]) --> 14\n",
      "tensor([ 0, 14]) --> 59\n",
      "tensor([ 0, 14, 59]) --> 58\n",
      "tensor([ 0, 14, 59, 58]) --> 1\n",
      "tensor([58]) --> 1\n",
      "tensor([58,  1]) --> 58\n",
      "tensor([58,  1, 58]) --> 53\n",
      "tensor([58,  1, 58, 53]) --> 1\n",
      "tensor([52]) --> 41\n",
      "tensor([52, 41]) --> 43\n",
      "tensor([52, 41, 43]) --> 12\n",
      "tensor([52, 41, 43, 12]) --> 0\n",
      "tensor([50]) --> 39\n",
      "tensor([50, 39]) --> 47\n",
      "tensor([50, 39, 47]) --> 52\n",
      "tensor([50, 39, 47, 52]) --> 43\n",
      "tensor([6]) --> 1\n",
      "tensor([6, 1]) --> 39\n",
      "tensor([ 6,  1, 39]) --> 52\n",
      "tensor([ 6,  1, 39, 52]) --> 42\n",
      "tensor([58]) --> 46\n",
      "tensor([58, 46]) --> 63\n",
      "tensor([58, 46, 63]) --> 0\n",
      "tensor([58, 46, 63,  0]) --> 45\n",
      "tensor([10]) --> 0\n",
      "tensor([10,  0]) --> 13\n",
      "tensor([10,  0, 13]) --> 1\n",
      "tensor([10,  0, 13,  1]) --> 52\n"
     ]
    }
   ],
   "source": [
    "def get_batch(split, bs):\n",
    "    d = train if split=='train' else val\n",
    "    ix = torch.randint(0, len(d) - block_size, (batch_size,))\n",
    "    xb = torch.stack([d[i   : i +   block_size] for i in ix], dim=0)\n",
    "    yb = torch.stack([d[i+1 : i+1 + block_size] for i in ix], dim=0)\n",
    "    return xb, yb\n",
    "\n",
    "xb, yb = get_batch('train', bs=batch_size)\n",
    "print(xb, '\\n', yb)\n",
    "print()\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        print(f'{xb[b, :t+1]} --> {yb[b, t]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95798f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RWz?CBdR?ire h?CmbyrcdWAh?ItPjR.bR\n",
      "YQ:&vt:XiVmbvfaLqqrub\n",
      "$m.I I\n",
      "UR.Sb!NcDosR;iW,kp.X$LPjSLFssvfBXW\n",
      "j\n"
     ]
    }
   ],
   "source": [
    "class BigramLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets = None):\n",
    "        logits = self.token_embedding_table(x) # (b, t, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # targets: (b, t)                                   --> (b*t)\n",
    "            # logits: (b, t, c) - c: channels --> (b, c, t)     --> (b*t, c)\n",
    "            # loss = F.cross_entropy(logits.transpose(-1,-2), targets)\n",
    "\n",
    "            B,T,C = logits.shape\n",
    "            logits_new = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits_new, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        # idx: (b, t)\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx) # (b, t, vocab_size)\n",
    "            logits = logits[:, -1, :] # (b, vocab_size)\n",
    "            probs = F.softmax(logits, dim=-1) # (b, vocab_size)\n",
    "            idx_new = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_new), dim=-1) # (b, t+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLM()\n",
    "logits, loss = model(xb, yb)\n",
    "# loss.item()\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model.generate(idx)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3b694a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "aac4e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item() = 2.319518804550171\n",
      "\n",
      "ARUShe, n:\n",
      "sopoh kld theritoman;\n",
      "HEx'retrear EY:\n",
      "RICorve wnsattldey st camefoman Seaisor,\n",
      "\n",
      "\n",
      "De t, ce\n"
     ]
    }
   ],
   "source": [
    "max_iters = 10000\n",
    "batch_size = 32\n",
    "\n",
    "for _ in range(max_iters):\n",
    "    # get a batch\n",
    "    xb, yb = get_batch('train', bs=batch_size)\n",
    "\n",
    "    # forward pass\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    # set grad to None and backward pass\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f'{loss.item() = }')\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model.generate(idx)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683282c",
   "metadata": {},
   "source": [
    "# Adding a diversion of `n_embd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "237db5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 250\n",
    "\n",
    "# evaluate loss\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x, y = get_batch(split, bs=batch_size)\n",
    "            _, loss = model(x, y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "44a9251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 32\n",
    "\n",
    "class BigramLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets = None):\n",
    "        tok_emb = self.token_embedding_table(x) # (b, t, n_embd)\n",
    "        logits = self.lm_head(tok_emb) # (b, t, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # targets: (b, t)                                   --> (b*t)\n",
    "            # logits: (b, t, c) - c: channels --> (b, c, t)     --> (b*t, c)\n",
    "            # loss = F.cross_entropy(logits.transpose(-1,-2), targets)\n",
    "\n",
    "            B,T,C = logits.shape\n",
    "            logits_new = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits_new, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens=100):\n",
    "        # idx: (b, t)\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx) # (b, vocab_size)\n",
    "            logits = logits[:, -1, :] # (b, vocab_size)\n",
    "            probs = F.softmax(logits, dim=-1) # (b, vocab_size)\n",
    "            idx_new = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_new), dim=-1) # (b, t+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLM()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "bbaef305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 : Train Loss = 2.4680, Validation Loss = 2.4836\n",
      "Iteration 1001 : Train Loss = 2.4524, Validation Loss = 2.4941\n",
      "Iteration 2001 : Train Loss = 2.4752, Validation Loss = 2.4974\n",
      "Iteration 3001 : Train Loss = 2.4602, Validation Loss = 2.5030\n",
      "Iteration 4001 : Train Loss = 2.4583, Validation Loss = 2.4882\n",
      "Iteration 5001 : Train Loss = 2.4788, Validation Loss = 2.4860\n",
      "Iteration 6001 : Train Loss = 2.4526, Validation Loss = 2.4920\n",
      "Iteration 7001 : Train Loss = 2.4560, Validation Loss = 2.4937\n",
      "Iteration 8001 : Train Loss = 2.4513, Validation Loss = 2.4783\n",
      "Iteration 9001 : Train Loss = 2.4677, Validation Loss = 2.4944\n"
     ]
    }
   ],
   "source": [
    "max_iters = 10000\n",
    "batch_size = 32\n",
    "eval_interval = 1000\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # get a batch\n",
    "    xb, yb = get_batch('train', bs=batch_size)\n",
    "\n",
    "    # forward pass\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    if iter % eval_interval == 0:\n",
    "        out = estimate_loss()\n",
    "        print(f'Iteration {iter + 1} : Train Loss = {out['train']:.4f}, Validation Loss = {out['val']:.4f}')\n",
    "\n",
    "    # set grad to None and backward pass\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "2dcdceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "unendesilowo'listrdealeraim.\n",
      "Bus llar he hest wevowarr ch ayotllthor t heavisen, ids ir bime t wive \n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model.generate(idx)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61309d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
