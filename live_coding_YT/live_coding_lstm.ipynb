{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c505f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138bc2c1",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0d4e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLoader:\n",
    "    def __init__(self, text, test_split=0.9):\n",
    "        self.vocab = sorted(list(set(text)))\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.stoi = {ch:i for i,ch in enumerate(self.vocab)}\n",
    "        self.itos = {i:ch for ch,i in self.stoi.items()}\n",
    "\n",
    "        self.data = [self.stoi[ch] for ch in text]\n",
    "        n = int(test_split * len(self.data))\n",
    "        self.train_data = self.data[:n]\n",
    "        self.val_data = self.data[n:]\n",
    "        \n",
    "    def encode(self, text):\n",
    "        # return list of char indices\n",
    "        return [self.stoi[ch] for ch in text]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        # return string for the tokens list\n",
    "        return ''.join([self.itos[token] for token in tokens])\n",
    "\n",
    "    def get_batch(self, split, batch_size, block_size):\n",
    "        data = self.train_data if split=='train' else self.val_data\n",
    "        ix = torch.randint(0, len(data) - block_size, (batch_size,)) # [2,99, 56, 9000,...]\n",
    "        x = [data[i : i + block_size] for i in ix]\n",
    "        y = [data[i+1 : i+1 + block_size] for i in ix]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b96066ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('../rnn_lstm/data/shakespeare.txt', 'r').read()\n",
    "loader = TextLoader(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4512ab25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TextLoader at 0x136f1ddf0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7b94d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "print(loader.vocab)\n",
    "print(loader.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "067130ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52, 58, 47, 52],\n",
      "        [47, 52, 43,  1]])\n",
      "tensor([[58, 47, 52, 59],\n",
      "        [52, 43,  1, 57]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = loader.get_batch('train', 2, 4)\n",
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e841e75",
   "metadata": {},
   "source": [
    "# Model construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    # prev_layer_hidden_state\n",
    "    def __init__(self, input_embd, hidden_embd):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        wx_gates: [wxf | wxi | wxg | wxo]\n",
    "        wh_gates: [whf | whi | whg | wxo]\n",
    "        b_gates : [bf | bi | bg | bo]\n",
    "        \"\"\"\n",
    "        self.wx_gates = nn.Parameter(torch.randn(input_embd, hidden_embd * 4) * 0.01)\n",
    "        self.wh_gates = nn.Parameter(torch.randn(hidden_embd, hidden_embd * 4) * 0.01)\n",
    "        self.b_gates = nn.Parameter(torch.zeros(hidden_embd * 4))\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        # x: (B,n)\n",
    "        # layer_hidden: (B,hidden_embd)\n",
    "        # layer_cell: (B,hidden_embd)\n",
    "        x_gates = x @ self.wx_gates # (b,input_dim) @ (inpyt_embd, hidden_embd*4) -> (b,hidden_embd*4)\n",
    "        h_gates = h_prev @ self.wh_gates # (b,hidden_embd) @ (hidden_embd, hidden_embd*4) -> (b,hidden_embd*4)\n",
    "        gates_output = x_gates + h_gates + self.b_gates\n",
    "\n",
    "        ft, it, gt, ot = gates_output.chunk(4, dim=1)\n",
    "\n",
    "        ft = torch.sigmoid(ft)\n",
    "        it = torch.sigmoid(it)\n",
    "        gt = torch.tanh(gt)\n",
    "        ot = torch.sigmoid(ot)\n",
    "\n",
    "        c_t = (ft * c_prev) + (it * gt)\n",
    "        h_t = ot * torch.tanh(c_t)\n",
    "        return h_t, c_t\n",
    "\n",
    "class MultiLayerLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, input_embd, hidden_embd, layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.hidden_embd = hidden_embd\n",
    "        self.embedding = nn.Parameter(torch.randn(vocab_size, input_embd) * 0.01)\n",
    "        self.lstm_layer = nn.ModuleList()\n",
    "        \n",
    "        self.lstm_layer.append(LSTMCell(input_embd, hidden_embd))\n",
    "        for layer in range(1, layers):\n",
    "            self.lstm_layer.append(LSTMCell(hidden_embd, hidden_embd))\n",
    "        self.dropout = nn.Dropout(dropout) if dropout is not None and layers > 1 else None\n",
    "\n",
    "        self.why = nn.Parameter(torch.randn(hidden_embd, vocab_size) * 0.01)\n",
    "        self.by = nn.Parameter(torch.zeros(vocab_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T = x.shape\n",
    "        hs = torch.zeros(self.layers, B, self.hidden_embd, device=x.device)\n",
    "        cs = torch.zeros(self.layers, B, self.hidden_embd, device=x.device)\n",
    "        logits = []\n",
    "\n",
    "        emb = self.embedding[x] # (B,T,input_embd)\n",
    "        \n",
    "        for t in range(T):\n",
    "            xt = emb[:, t, :] # (B, input_embd)\n",
    "            hs_new = torch.zeros_like(hs, device=xt.device)\n",
    "            cs_new = torch.zeros_like(cs, device=xt.device)\n",
    "            for layer in range(self.layers):\n",
    "                h_layer, c_layer = hs[layer], cs[layer]\n",
    "                cell_layer = self.lstm_layer[layer]\n",
    "                h_new, c_new = cell_layer(xt, h_layer, c_layer)\n",
    "                hs_new[layer] = h_new\n",
    "                cs_new[layer] = c_new\n",
    "                if layer < self.layers - 1 and self.dropout is not None:\n",
    "                    xt = self.dropout(h_new)\n",
    "                else:\n",
    "                    xt = h_new\n",
    "            hs = hs_new\n",
    "            cs = cs_new\n",
    "            yt = hs[-1] @ self.why + self.by # (B, vocab_size)\n",
    "            logits.append(yt)\n",
    "        # now logits: T elements of shape (B, vocab_size)\n",
    "        logits = torch.stack(logits, dim=1) # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a203f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16233\n"
     ]
    }
   ],
   "source": [
    "n_embd = 8\n",
    "n_hidden = 32\n",
    "device = 'mps'\n",
    "\n",
    "model = MultiLayerLSTM(loader.vocab_size, input_embd=n_embd, hidden_embd=n_hidden, layers=2)\n",
    "model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05bf0fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MultiLayerLSTM"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1784970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding torch.Size([65, 8])\n",
      "why torch.Size([32, 65])\n",
      "by torch.Size([65])\n",
      "lstm_layer.0.wx_gates torch.Size([8, 128])\n",
      "lstm_layer.0.wh_gates torch.Size([32, 128])\n",
      "lstm_layer.0.b_gates torch.Size([128])\n",
      "lstm_layer.1.wx_gates torch.Size([32, 128])\n",
      "lstm_layer.1.wh_gates torch.Size([32, 128])\n",
      "lstm_layer.1.b_gates torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bbc3ab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.074433 MILION params\n",
      "Iteration 0 | train loss = 4.1744 | val loss = 4.1733\n",
      "Iteration 100 | train loss = 3.3609 | val loss = 4.1733\n",
      "Iteration 200 | train loss = 3.3098 | val loss = 3.3687\n",
      "Iteration 300 | train loss = 3.1805 | val loss = 3.3687\n",
      "Iteration 400 | train loss = 3.0694 | val loss = 3.0908\n",
      "Iteration 500 | train loss = 2.9918 | val loss = 3.0908\n",
      "Iteration 600 | train loss = 2.8405 | val loss = 2.8516\n",
      "Iteration 700 | train loss = 2.7169 | val loss = 2.8516\n",
      "Iteration 800 | train loss = 2.6768 | val loss = 2.6684\n",
      "Iteration 900 | train loss = 2.5953 | val loss = 2.6684\n",
      "Iteration 1000 | train loss = 2.5885 | val loss = 2.5853\n",
      "Iteration 1100 | train loss = 2.5803 | val loss = 2.5853\n",
      "Iteration 1200 | train loss = 2.5681 | val loss = 2.5234\n",
      "Iteration 1300 | train loss = 2.4880 | val loss = 2.5234\n",
      "Iteration 1400 | train loss = 2.4933 | val loss = 2.4724\n",
      "Iteration 1500 | train loss = 2.4619 | val loss = 2.4724\n",
      "Iteration 1600 | train loss = 2.4093 | val loss = 2.4229\n",
      "Iteration 1700 | train loss = 2.4148 | val loss = 2.4229\n",
      "Iteration 1800 | train loss = 2.3634 | val loss = 2.3701\n",
      "Iteration 1900 | train loss = 2.3328 | val loss = 2.3701\n",
      "Iteration 2000 | train loss = 2.3625 | val loss = 2.3309\n",
      "Iteration 2100 | train loss = 2.2538 | val loss = 2.3309\n",
      "Iteration 2200 | train loss = 2.3253 | val loss = 2.2848\n",
      "Iteration 2300 | train loss = 2.2385 | val loss = 2.2848\n",
      "Iteration 2400 | train loss = 2.2089 | val loss = 2.2573\n",
      "Iteration 2500 | train loss = 2.2136 | val loss = 2.2573\n",
      "Iteration 2600 | train loss = 2.1915 | val loss = 2.2302\n",
      "Iteration 2700 | train loss = 2.2138 | val loss = 2.2302\n",
      "Iteration 2800 | train loss = 2.1690 | val loss = 2.2037\n",
      "Iteration 2900 | train loss = 2.1992 | val loss = 2.2037\n",
      "Iteration 3000 | train loss = 2.1640 | val loss = 2.1830\n",
      "Iteration 3100 | train loss = 2.0996 | val loss = 2.1830\n",
      "Iteration 3200 | train loss = 2.1916 | val loss = 2.1501\n",
      "Iteration 3300 | train loss = 2.1059 | val loss = 2.1501\n",
      "Iteration 3400 | train loss = 2.0477 | val loss = 2.1498\n",
      "Iteration 3500 | train loss = 2.0730 | val loss = 2.1498\n",
      "Iteration 3600 | train loss = 2.0904 | val loss = 2.1358\n",
      "Iteration 3700 | train loss = 2.0153 | val loss = 2.1358\n",
      "Iteration 3800 | train loss = 2.0653 | val loss = 2.1305\n",
      "Iteration 3900 | train loss = 1.9952 | val loss = 2.1305\n",
      "Iteration 4000 | train loss = 2.0251 | val loss = 2.1079\n",
      "Iteration 4100 | train loss = 2.0352 | val loss = 2.1079\n",
      "Iteration 4200 | train loss = 2.0256 | val loss = 2.1028\n",
      "Iteration 4300 | train loss = 2.0222 | val loss = 2.1028\n",
      "Iteration 4400 | train loss = 1.9914 | val loss = 2.0860\n",
      "Iteration 4500 | train loss = 1.9893 | val loss = 2.0860\n",
      "Iteration 4600 | train loss = 2.0445 | val loss = 2.0907\n",
      "Iteration 4700 | train loss = 1.9737 | val loss = 2.0907\n",
      "Iteration 4800 | train loss = 1.9736 | val loss = 2.0603\n",
      "Iteration 4900 | train loss = 1.9482 | val loss = 2.0603\n",
      "Iteration 5000 | train loss = 1.9866 | val loss = 2.0651\n",
      "Iteration 5100 | train loss = 1.9237 | val loss = 2.0651\n",
      "Iteration 5200 | train loss = 1.9545 | val loss = 2.0642\n",
      "Iteration 5300 | train loss = 1.9842 | val loss = 2.0642\n",
      "Iteration 5400 | train loss = 1.8726 | val loss = 2.0418\n",
      "Iteration 5500 | train loss = 1.9725 | val loss = 2.0418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m B,T = x.shape\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m loss = F.cross_entropy(logits.view(B*T, -\u001b[32m1\u001b[39m), y.view(B*T))\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mMultiLayerLSTM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     66\u001b[39m cs_new[layer] = c_new\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m layer < \u001b[38;5;28mself\u001b[39m.layers - \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     70\u001b[39m     xt = h_new\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch/lib/python3.12/site-packages/torch/nn/functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_embd = 64\n",
    "n_hidden = 64\n",
    "device = 'mps'\n",
    "batch_size = 32\n",
    "block_size = 128\n",
    "\n",
    "model = MultiLayerLSTM(loader.vocab_size, input_embd=n_embd, hidden_embd=n_hidden, layers=2)\n",
    "model.to(device)\n",
    "print(f'{sum(p.numel() for p in model.parameters()) / 1e6} MILION params')\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_iters = 20000\n",
    "patience = 20\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for i in range(max_iters):\n",
    "    x, y = loader.get_batch('train', batch_size=batch_size, block_size=block_size)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    B,T = x.shape\n",
    "    # forward pass\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits.view(B*T, -1), y.view(B*T))\n",
    "\n",
    "    # backward pass\n",
    "    for p in model.parameters():\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights\n",
    "    optim.step()\n",
    "\n",
    "    # validation\n",
    "    if i % 200 == 0:\n",
    "        with torch.no_grad():\n",
    "            x_val, y_val = loader.get_batch('val', batch_size=512, block_size=block_size)\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            logits = model(x_val)\n",
    "            val_loss = F.cross_entropy(logits.view(-1, loader.vocab_size), y_val.view(-1))\n",
    "        # early-stopping\n",
    "        if val_loss < best_val_loss - 1e-4: # small delta to be considered\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        if epochs_no_improve > patience:\n",
    "            print(f'Early stop @ epoch {i}. \\n__________________Best validation loss = {best_val_loss:.4f}')\n",
    "            break\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration {i} | train loss = {loss.item():.4f} | val loss = {val_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58ce4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, stoi, itos, block_size, prompt=None, device='cpu', max_new_tokens=500, out_path='generated.txt'):\n",
    "    model.eval()\n",
    "    if not prompt:\n",
    "        idx = torch.tensor([[0]], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        idx = torch.tensor([loader.stoi[ch] for ch in prompt], dtype=torch.long, device=device)\n",
    "    generated_chars = []\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cropped = idx[:, -block_size:] # (b,T)\n",
    "        logits = model(idx_cropped) # (b,T,vocab_size)\n",
    "        logits = logits[0][-1] # (vocab_size,) vector from last time step\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_idx = torch.multinomial(probs, 1).item()\n",
    "        generated_chars.append(loader.itos[next_idx])\n",
    "    full_text = ''.join(generated_chars)\n",
    "    print(full_text)\n",
    "    # with open(out_path, 'w', encoding='utf-8') as fp:\n",
    "    #     fp.write(full_text)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "efafe0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBIBHSHwLHI:TgDy'y:AwI\n",
      "ucKRLLTlurHWAMGtE\n",
      "W'HS';OSWSlSI;p3FsPI;CoiIEyHrMb\n",
      "HPR\n",
      "aTcZKVM3ACI sLTE3VWgaOO-E3DRIIIAANTAb-HQoI UNVAlRVHIDEdCMHT\n",
      "BFHLcHOlGPSW\n",
      "-HObsGaxbJHIQTOOJRMCHBH,CHPMPIILKCCM'WNGiHWntU3IfmFBO\n",
      "bEFKlIEILOq,Hp:HHENHoPv WI\n",
      "pOnOFHngN\n",
      "POOIRNCBHDiVaUIAjyEIWIcFMBnOGOLEBIP\n",
      "muK\n",
      "wbhCGHtJYeCEeVREiL-KHGE IaEWEMKTgiNIaENLTEvCMLF I\n",
      "W\n",
      "VrBlmtWCWuN FEAVVAb\n",
      "WCRhnVIRIaCiSLiI V3fBTAw\n",
      "jnv\n",
      "bMTIBaMtL\n",
      "LktFFhYSwFIIDDFEN'SBSNYSZHUAulSwJBIrMaOUF\n",
      "GBMmOH ,M&rWCI\n",
      "AKQDgauD\n",
      "DS,MCeWT\n",
      "MAOEoSKtKLRACNHEGkFETwHwGTINTDAHT\n"
     ]
    }
   ],
   "source": [
    "generate(model, loader.stoi, loader.itos, block_size=block_size, device='mps', max_new_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93364687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
