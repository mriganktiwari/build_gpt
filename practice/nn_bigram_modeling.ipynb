{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb880c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d748560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33de87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['.'] + sorted(list(set(''.join(words))))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# mapping from char to integer, to fill the matrix\n",
    "stoi = {ch: i for i,ch in enumerate(vocab)}\n",
    "\n",
    "# inverse map, to decode while generation\n",
    "itos = {i: ch for ch,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b4ee5",
   "metadata": {},
   "source": [
    "### Construct input and outputs to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ba56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        xs.append(stoi[ch1])\n",
    "        ys.append(stoi[ch2])\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "# type(xs), type(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453a6d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 5\n",
      "5 - 13\n",
      "13 - 13\n",
      "13 - 1\n",
      "1 - 0\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(xs, ys):\n",
    "    print(f'{x} - {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474a5380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=vocab_size).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2cfa891",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "339bd77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4541, -0.0247, -0.1751,  0.0575, -0.6052,  0.7173, -0.5617,  0.2876,\n",
       "         -0.5594,  0.8084, -0.5060,  0.9233, -1.7278, -2.2319,  0.7681, -0.5404,\n",
       "         -0.2720,  0.5720, -0.0392, -1.2653,  0.7015,  0.7822, -0.9689, -0.8191,\n",
       "          0.6100,  0.6062, -1.3918],\n",
       "        [ 0.8898, -0.2148,  0.5852,  0.5912,  0.6323, -1.1569, -0.0847, -1.8790,\n",
       "          1.7973,  1.4554,  0.0233,  1.6183,  1.0714,  0.7000,  0.6594, -1.0429,\n",
       "          1.6146,  0.1018, -1.9442, -0.3743,  0.0463, -0.7652,  0.2598,  0.5734,\n",
       "         -0.9370,  1.1055, -1.6889],\n",
       "        [ 1.3131,  0.0084,  0.2310,  1.2991,  1.8917,  0.9315, -0.2191, -0.5848,\n",
       "         -0.4077, -2.2127, -1.7800, -0.6531,  1.3630,  0.4454,  1.2610, -2.1095,\n",
       "         -0.3351,  0.5288, -0.6718,  1.2187,  1.0076,  1.3114,  0.4003,  0.0995,\n",
       "          0.3241, -0.3780,  1.0680],\n",
       "        [ 1.3131,  0.0084,  0.2310,  1.2991,  1.8917,  0.9315, -0.2191, -0.5848,\n",
       "         -0.4077, -2.2127, -1.7800, -0.6531,  1.3630,  0.4454,  1.2610, -2.1095,\n",
       "         -0.3351,  0.5288, -0.6718,  1.2187,  1.0076,  1.3114,  0.4003,  0.0995,\n",
       "          0.3241, -0.3780,  1.0680],\n",
       "        [ 0.1762,  0.7898,  0.3428, -0.4484, -1.9759,  0.3263,  0.2850,  0.7824,\n",
       "         -0.1892,  0.4668, -0.7159,  1.2281, -0.0687,  0.9882,  0.2869,  0.6689,\n",
       "          0.1095,  0.0613,  0.9556,  0.0725, -0.5819, -0.1800,  0.3088,  0.1735,\n",
       "          0.8432,  1.4062, -1.0359]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc @ W) # (5,27) @ (27,27) -> (5,27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c628ea",
   "metadata": {},
   "source": [
    "### How to interpret these 27 outputs for any sample\n",
    "- probability distribution over 27 characters in our vocab\n",
    "- we want to think of these as a row in the probability matrix, which is calculated from input car\n",
    "- think of these numbers as log-counts, exponentiating these gets us counts (all positives)\n",
    "- then normalize to sum to 1, for a row (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10855778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.exp(xenc @ W) / torch.exp(xenc @ W).sum(dim=1, keepdim=True)\n",
    "probs.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1371ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        xs.append(stoi[ch1])\n",
    "        ys.append(stoi[ch2])\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=vocab_size).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23eca8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146]), torch.Size([228146]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ceb3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758953094482422\n",
      "3.371100664138794\n",
      "3.154043197631836\n",
      "3.020373821258545\n",
      "2.927711248397827\n",
      "2.8604023456573486\n",
      "2.8097290992736816\n",
      "2.7701022624969482\n",
      "2.7380731105804443\n",
      "2.711496353149414\n",
      "2.6890032291412354\n",
      "2.6696884632110596\n",
      "2.6529300212860107\n",
      "2.638277292251587\n",
      "2.6253879070281982\n",
      "2.613990545272827\n",
      "2.60386323928833\n",
      "2.5948216915130615\n",
      "2.5867116451263428\n",
      "2.5794036388397217\n",
      "2.572789192199707\n",
      "2.5667762756347656\n",
      "2.5612881183624268\n",
      "2.5562589168548584\n",
      "2.551633596420288\n",
      "2.547366142272949\n",
      "2.543415069580078\n",
      "2.5397486686706543\n",
      "2.536336660385132\n",
      "2.533154249191284\n",
      "2.5301806926727295\n",
      "2.5273966789245605\n",
      "2.5247862339019775\n",
      "2.522334575653076\n",
      "2.520029067993164\n",
      "2.517857789993286\n",
      "2.515810489654541\n",
      "2.513878345489502\n",
      "2.512052059173584\n",
      "2.510324001312256\n",
      "2.5086867809295654\n",
      "2.5071346759796143\n",
      "2.5056614875793457\n",
      "2.504261016845703\n",
      "2.5029289722442627\n",
      "2.5016613006591797\n",
      "2.5004520416259766\n",
      "2.4992988109588623\n",
      "2.498197317123413\n",
      "2.497144937515259\n",
      "2.496137857437134\n",
      "2.495173692703247\n",
      "2.4942493438720703\n",
      "2.493363380432129\n",
      "2.4925124645233154\n",
      "2.4916954040527344\n",
      "2.4909095764160156\n",
      "2.4901540279388428\n",
      "2.4894261360168457\n",
      "2.488725185394287\n",
      "2.488049268722534\n",
      "2.4873976707458496\n",
      "2.4867680072784424\n",
      "2.4861605167388916\n",
      "2.4855728149414062\n",
      "2.4850046634674072\n",
      "2.4844553470611572\n",
      "2.4839231967926025\n",
      "2.483407735824585\n",
      "2.4829084873199463\n",
      "2.482424736022949\n",
      "2.481955051422119\n",
      "2.481499195098877\n",
      "2.4810571670532227\n",
      "2.4806275367736816\n",
      "2.480210065841675\n",
      "2.479804515838623\n",
      "2.479410171508789\n",
      "2.4790265560150146\n",
      "2.4786534309387207\n",
      "2.478290319442749\n",
      "2.4779369831085205\n",
      "2.477592706680298\n",
      "2.477257251739502\n",
      "2.4769301414489746\n",
      "2.476611852645874\n",
      "2.4763007164001465\n",
      "2.4759979248046875\n",
      "2.4757025241851807\n",
      "2.4754140377044678\n",
      "2.475132703781128\n",
      "2.474858045578003\n",
      "2.4745898246765137\n",
      "2.474327564239502\n",
      "2.474071741104126\n",
      "2.4738216400146484\n",
      "2.4735772609710693\n",
      "2.4733383655548096\n",
      "2.47310471534729\n",
      "2.4728758335113525\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    n = xenc.shape[0]\n",
    "    # forward pass\n",
    "    logits = xenc @ W\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # calculate loss\n",
    "    # we need to pluck probabilities assigned to correct indices from out calculated `probs`\n",
    "\n",
    "    loss = - probs[torch.arange(n),ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None  # same as setting gradients = 0.\n",
    "    loss.backward()\n",
    "\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c263815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.\n",
      "mma.\n",
      "asttlerabruiona.\n",
      "bejolicori.\n",
      "s.\n"
     ]
    }
   ],
   "source": [
    "# g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        x = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = x @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998b89c",
   "metadata": {},
   "source": [
    "#### Adding regularization / same as smoothing in count based modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "742ae958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((vocab_size, vocab_size), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "933fc294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.76861834526062\n",
      "3.3788065910339355\n",
      "3.161090850830078\n",
      "3.0271859169006348\n",
      "2.9344842433929443\n",
      "2.867231607437134\n",
      "2.8166542053222656\n",
      "2.777146339416504\n",
      "2.7452542781829834\n",
      "2.7188305854797363\n",
      "2.696505546569824\n",
      "2.6773719787597656\n",
      "2.6608054637908936\n",
      "2.6463515758514404\n",
      "2.633665084838867\n",
      "2.622471570968628\n",
      "2.6125476360321045\n",
      "2.6037068367004395\n",
      "2.595794439315796\n",
      "2.5886809825897217\n",
      "2.582256317138672\n",
      "2.5764293670654297\n",
      "2.5711236000061035\n",
      "2.566272735595703\n",
      "2.5618226528167725\n",
      "2.5577261447906494\n",
      "2.5539445877075195\n",
      "2.550442695617676\n",
      "2.5471930503845215\n",
      "2.5441696643829346\n",
      "2.5413525104522705\n",
      "2.538722038269043\n",
      "2.536262035369873\n",
      "2.5339579582214355\n",
      "2.531797409057617\n",
      "2.5297679901123047\n",
      "2.527860164642334\n",
      "2.526063919067383\n",
      "2.5243709087371826\n",
      "2.522773265838623\n",
      "2.52126407623291\n",
      "2.519836664199829\n",
      "2.5184855461120605\n",
      "2.517204999923706\n",
      "2.515990972518921\n",
      "2.5148372650146484\n",
      "2.5137410163879395\n",
      "2.512698173522949\n",
      "2.511704444885254\n",
      "2.5107579231262207\n",
      "2.509855031967163\n",
      "2.5089924335479736\n",
      "2.5081682205200195\n",
      "2.5073797702789307\n",
      "2.5066258907318115\n",
      "2.5059030055999756\n",
      "2.5052106380462646\n",
      "2.5045459270477295\n",
      "2.5039076805114746\n",
      "2.503295421600342\n",
      "2.5027060508728027\n",
      "2.5021398067474365\n",
      "2.501594305038452\n",
      "2.5010693073272705\n",
      "2.500563383102417\n",
      "2.500075101852417\n",
      "2.4996049404144287\n",
      "2.4991507530212402\n",
      "2.4987120628356934\n",
      "2.49828839302063\n",
      "2.4978790283203125\n",
      "2.4974827766418457\n",
      "2.4970996379852295\n",
      "2.4967291355133057\n",
      "2.496370315551758\n",
      "2.496022939682007\n",
      "2.4956860542297363\n",
      "2.4953596591949463\n",
      "2.4950432777404785\n",
      "2.4947361946105957\n",
      "2.494438886642456\n",
      "2.494149684906006\n",
      "2.4938690662384033\n",
      "2.4935967922210693\n",
      "2.4933323860168457\n",
      "2.493075132369995\n",
      "2.4928252696990967\n",
      "2.492582321166992\n",
      "2.4923462867736816\n",
      "2.492116689682007\n",
      "2.4918930530548096\n",
      "2.491675853729248\n",
      "2.491464614868164\n",
      "2.491258382797241\n",
      "2.491058349609375\n",
      "2.4908626079559326\n",
      "2.4906723499298096\n",
      "2.4904870986938477\n",
      "2.4903063774108887\n",
      "2.4901304244995117\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    n = xenc.shape[0]\n",
    "    # forward pass\n",
    "    logits = xenc @ W\n",
    "    counts = torch.exp(logits)\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # calculate loss\n",
    "    # we need to pluck probabilities assigned to correct indices from out calculated `probs`\n",
    "\n",
    "    loss = -probs[torch.arange(n),ys].log().mean() + 0.01 * (W**2).mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # same as setting gradients = 0.\n",
    "    loss.backward()\n",
    "\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213e409",
   "metadata": {},
   "source": [
    "## Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55c3cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze.\n",
      "momasurailezityha.\n",
      "konimittain.\n",
      "llayn.\n",
      "ka.\n",
      "da.\n",
      "staiyaubrtthrigotai.\n",
      "moliellavo.\n",
      "ke.\n",
      "teda.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        x = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = x @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60353f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d57c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23840c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33327e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
