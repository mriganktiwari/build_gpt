{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5551de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1209fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89e34ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15, 32033)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum and maximum length of names in file\n",
    "min([len(w) for w in words]), max([len(w) for w in words]), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf490eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afe618",
   "metadata": {},
   "source": [
    "- As we plan to do next char prediction\n",
    "- one word goes as input, the next should be output\n",
    "- Every word must be starting & ending with a identifier\n",
    "- We can do distinct identifiers for both or same\n",
    "- [\\S, e, m, m, a, \\E] be the chars\n",
    "- Also, [., e, m, m, a, .] ca be possible\n",
    "\n",
    "### Let's look at how the input-output pairs would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d089fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". -> e\n",
      "e -> m\n",
      "m -> m\n",
      "m -> a\n",
      "a -> .\n"
     ]
    }
   ],
   "source": [
    "for w in words[:3]:\n",
    "    list_w = list('.' + w + '.')\n",
    "    # print(''.join(list_w))\n",
    "    for ch1, ch2 in zip(list_w[:-1], list_w[1:]):\n",
    "        print(f'{ch1} -> {ch2}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ce88f",
   "metadata": {},
   "source": [
    "- So our generative model:\n",
    "- starts with an initial input `'.'`, which shoul trigger name generation\n",
    "- and shall continue generating unless another `'.'` char is generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3300ecf",
   "metadata": {},
   "source": [
    "### Counting bi-grams in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a257ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "for w in words:\n",
    "    chars = list('.' + w + '.')\n",
    "    for ch1, ch2 in zip(chars[:-1], chars[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        count_dict[bigram] = count_dict.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c695bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '.'), 6763),\n",
       " (('a', '.'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('.', 'a'), 4410),\n",
       " (('e', '.'), 3983)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can look at most or least occuring bigrams in the data: by sorting count_dict\n",
    "\n",
    "# sorted(count_dict.items()) # sorts on the first items, i.e. keys (the bigram pairs)\n",
    "sorted_counts = sorted(count_dict.items(), key=lambda kv: -kv[1])\n",
    "sorted_counts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91507cb5",
   "metadata": {},
   "source": [
    "- For predicting next char based on a char\n",
    "- On basis of counts\n",
    "- We can store bigram counts in a 2-d array\n",
    "- `row` will denote input char\n",
    "- `col` will be prob of predicted char\n",
    "- In our case, size of array would be 27x27\n",
    "- coz, vocab constitutes: 26 alphabets + ',' = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b34d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09635954",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['.'] + sorted(list(set(''.join(words))))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# mapping from char to integer, to fill the matrix\n",
    "stoi = {ch: i for i,ch in enumerate(vocab)}\n",
    "\n",
    "# inverse map, to decode while generation\n",
    "itos = {i: ch for ch,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f49f89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = torch.zeros((vocab_size, vocab_size), dtype=torch.int)\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d890f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets fill the matrix now\n",
    "N = torch.zeros((vocab_size, vocab_size), dtype=torch.int)\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29aa1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7245f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127301df0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIUBJREFUeJzt3X1s1Ne95/HP+GlszHiAEHvGwXG9veS2AkrbQCEoDxA1Vry3bBNSLUmkCqQ2SsrDCjlRthRp4+1KOEoVxB80VI0qCmpo2ZWSNFegJK4IphGlIixRuCSbkhunuBe7Lr7gMcYeP/32j16mnZiHnMPMfGfs90saCc/M1+fMmTPz8Y+Z+U4oCIJAAAAYKLKeAABg6iKEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYKbEegKfNj4+rrNnzyoSiSgUCllPBwDgKAgC9ff3q7a2VkVF1z7WybsQOnv2rOrq6qynAQC4QZ2dnZozZ841r5N3IRSJRCRJH3V0KlJV5VT7X1444jzetlULnGskKTky7lU3Nu7XJamk2P2osH52pddYQyNjXnXDY+5rUl5S7DXW4Y6/eNX98cKQc829n5vtNdYHvX1edYtvucmrrjoSdq4Z9dyPleV+Tx3vd7qvyfnkiNdYtVXlXnX/qXq6c83QsN9jJlTk9789pR7PB5I0MDTqXHPR47Zd7O/X3V+Zm3o+v5ashdALL7ygH/3oR+rq6tK8efO0fft23XXXXdetu/xfcJGqKlU5hlBJufuT7vSI2xiXlXqGkO+D3mfTRar8QqjUN4RGPUKo1C+EKqa7h4kklY+UOtf47pGKpN8e8R0vUpW7EJruGUKVEffxkqXDXmNNj1R41VVVuYdQqWcIFeU4hIrK3EMolPS7bZI+00sqWXljwr59+7Rp0yZt2bJFJ06c0F133aWmpiadOXMmG8MBAApUVkJo27Zt+s53vqPvfve7+uIXv6jt27errq5OO3fuzMZwAIAClfEQGh4e1vHjx9XY2Jh2fmNjo44ccX/NBgAweWX8NaFz585pbGxMNTU1aefX1NSou7t7wvWTyaSSyWTq50QikekpAQDyVNY+rPrpF6SCILjii1Stra2KRqOpE2/PBoCpI+MhNHv2bBUXF0846unp6ZlwdCRJmzdvVl9fX+rU2dmZ6SkBAPJUxkOorKxMt99+u9ra2tLOb2tr07JlyyZcPxwOq+o/3o5d5fG2bABA4crK54Sam5v17W9/W4sWLdIdd9yhn/70pzpz5oyeeOKJbAwHAChQWQmh1atXq7e3Vz/84Q/V1dWl+fPn68CBA6qvr8/GcACAApW1jgnr1q3TunXrsvXrAQCTQN71jrvs1q9vVqjYrQ3Jx7951nkc3z7dvu02zg/49cGaVube3qa81O8lv3CJX93+D7qcaz4X8Wst9M15tV51F5PubUte/8PEjxZ8FvNuinrVrfgfB7zqOl74lnONX9Me/8fN/3nffS2/u8jvHbO+rYUGPVrwJDx6sknS7OllXnWB5x33fzsvONcsrp/pXFM08tnXnu8TAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYCYUBL6t8LIjkUgoGo3q33rOO3/B3fDouPN4FR6NQaWJX1/+WY2P+y33+YFh55qbIm4NYG+Uz1byuc8kKVzqd7/5GPO8z4o9m9z68plnrufYdWHIuSY+ozwLM7k6n33s+3yQa7naI4lEQjU3RdXX13fd53GOhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZkqsJ3A1oVDIuTNtYnDUeZxpYb8l8G0+XuTZtTjX3Y599F507/Q93XP9fQ0OjznXlBb7rn1u77Mhj9tWWZ7b9a+pyl1n9zz7ggBcBUdCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzedtFe2BoVEVlbl2xE4MjzuPEZpQ710hy7vB92ejYuFddTyLpXDOjssxrLF8zppU611y45H6fSVJ5WbFXXYVH3fi4XzdmujhPNJB073Q/3bPTt+9jdMzj/vZutJ5jw6Puzz8+jxkXHAkBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwk7cNTP/by++ptGK6U82Pv/Ul53F8G4r6So7kbjyfRoxSbhtvjo75jeXbVNRnTf5n2x+8xtq47HNedfs/7Paqe/TLdc41vnukuMivY+eJzgvONf9ws9vzwGW+jTejFe6NeH2aJ0tSxLM5q+/99ue+IeeaW2ZWONeMODRK5UgIAGCGEAIAmCGEAABmMh5CLS0tCoVCaadYLJbpYQAAk0BW3pgwb948/eY3v0n9XFyc3W/mAwAUpqyEUElJCUc/AIDrysprQqdPn1Ztba0aGhr08MMP6+OPP77qdZPJpBKJRNoJADA1ZDyElixZoj179uiNN97Qiy++qO7ubi1btky9vb1XvH5ra6ui0WjqVFfn/lkHAEBhyngINTU16aGHHtKCBQv09a9/Xfv375ck7d69+4rX37x5s/r6+lKnzs7OTE8JAJCnst4xobKyUgsWLNDp06eveHk4HFY4HM72NAAAeSjrnxNKJpP64IMPFI/Hsz0UAKDAZDyEnnrqKbW3t6ujo0O///3v9a1vfUuJREJr1qzJ9FAAgAKX8f+O+9Of/qRHHnlE586d080336ylS5fq6NGjqq+vz/RQAIACFwpy2TL5M0gkEopGozr7lwuqqqpyqh3x6IhdXloYH6T16fbt2+k4FPKr8+HSbffvlZbQcerTfDqLF3nuEV8++7ikmPu60CQSCdXcFFVfX991n8e5dwEAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZrL+zaq+giCQa4Nvny7ChWLYo9v0tHBu796B5KhzTWkBdEj2bTTv243cd7xC2P0+D9FcN/r3maNvx/pc81nLbHfVz/9nAADApEUIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMJO3XbT3v9+liukXnWoqSoqdx/mneXHnGguXhseca3LdRbvSY7yeRNJrrOqqsFedTxfhkTG/Ls5Fodx2fx71mGdxmftjplD4Nt/26cbv20Q72x2qP82nG3+4NLt7hCMhAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZvK2genY+LjGxt2a7V0acW88ODrm3tBPkgaS7g1FJf9Gh3/qHXSumVlZ5jXWpeSoV51Pw9SbpvvN0afJpCQNeNy2s+eHvMaqnVnuVfe7T3q96hbVzXKuKSvx+zvUt+/muX73hrUXh/z2o2+T2+nl7vs4OeL3PFLu2UB2zHP/X7g04lwTrXAfZ8ih4TJHQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM6EgCPzasWZJIpFQNBpV118uqKqqyqn2g7P9zuPNm+M2hpX+Qffut5GK0izM5Op8tpJvN+CSYv5++rQ+nw7J03K7RwrB8Kh7R2zfbuSTVSKRUM1NUfX19V33eZyVAwCYIYQAAGacQ+jw4cNauXKlamtrFQqF9Oqrr6ZdHgSBWlpaVFtbq4qKCi1fvlynTp3K1HwBAJOIcwgNDAxo4cKF2rFjxxUvf+6557Rt2zbt2LFDx44dUywW03333af+fvfXawAAk5vz99g2NTWpqanpipcFQaDt27dry5YtWrVqlSRp9+7dqqmp0d69e/X444/f2GwBAJNKRl8T6ujoUHd3txobG1PnhcNh3XPPPTpy5MgVa5LJpBKJRNoJADA1ZDSEuru7JUk1NTVp59fU1KQu+7TW1lZFo9HUqa6uLpNTAgDksay8Oy4UCqX9HATBhPMu27x5s/r6+lKnzs7ObEwJAJCHnF8TupZYLCbpr0dE8Xg8dX5PT8+Eo6PLwuGwwuFwJqcBACgQGT0SamhoUCwWU1tbW+q84eFhtbe3a9myZZkcCgAwCTgfCV28eFEfffRR6ueOjg69++67mjVrlm699VZt2rRJW7du1dy5czV37lxt3bpV06ZN06OPPprRiQMACp9zCL3zzjtasWJF6ufm5mZJ0po1a/Tzn/9cTz/9tAYHB7Vu3TqdP39eS5Ys0ZtvvqlIJJK5WQMAJgUamNLANGNoYGqLBqaZQQPTG+fSwDSjb0zIpKGRMZWOjDnXTFb9Q6PONbkOoaER9wevzwNekqLTcvegHx3zm2Oug7Kk+MrvQM0nPmt5tXfWXk9xkV9daQ7X0fcYwHdNBjyeRyrLsxsTxDcAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzedvA9Oz5QU0fdWvA+S+9fc7jfPVzM5xrJP8Ggr7NMP/3ybPONZvu/rzXWL4qyoqda/75fffbJUn/9ct1XnU+/vXPA151c2PTveqKPBtvXkq6N/CtDOf2KcCnqatvp/VxzzqfRsjlpe57X/K/r3199OeLzjUL62dkfiJ/hyMhAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAICZvO2iXV1VrkhVuVNN0b+5d6T17dDr0QxYkl8XYUl6+Eu3+A2Y574Sm2k9hev6x9qIV93IqF/HdN/OyuFS970VBH7737eLvM/jzbfRtO8cy0rc1zHX3bB9/WPcby9nE0dCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzedtFe/5/3qxQcZlTzZYfbXIex7erdXJkzKsuMTjqVXfh0ohzTWyGWxfyy4aG/W5beVmxc01i0P12Sf7dn33KRj07rft0Y5akt0+f86pbcEvUuca307Qvn2bTyRG/buQjY35108LuT4vjnnsk1923hz3WpGTMfY6jDuNwJAQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMJO3XbR//+r/UiRS5VRTXRV2Hsel2+vfK/bsfhudVupVN7PSvc6303S41O9vk5FR97X8Sv0Mr7F8uz/7rEn/kF/n88qwe1dxSeq+NORVtzQ8y7lmzLP7s+/+/+O5S841Myvduulf5rv+PvvYdz3GPR+jvuNVenQI9xmpyOHxyZEQAMAMIQQAMOMcQocPH9bKlStVW1urUCikV199Ne3ytWvXKhQKpZ2WLl2aqfkCACYR5xAaGBjQwoULtWPHjqte5/7771dXV1fqdODAgRuaJABgcnJ+laqpqUlNTU3XvE44HFYsFvOeFABgasjKa0KHDh1SdXW1brvtNj322GPq6em56nWTyaQSiUTaCQAwNWQ8hJqamvTSSy/p4MGDev7553Xs2DHde++9SiaTV7x+a2urotFo6lRXV5fpKQEA8lTGPye0evXq1L/nz5+vRYsWqb6+Xvv379eqVasmXH/z5s1qbm5O/ZxIJAgiAJgisv5h1Xg8rvr6ep0+ffqKl4fDYYXD7h8yBQAUvqx/Tqi3t1ednZ2Kx+PZHgoAUGCcj4QuXryojz76KPVzR0eH3n33Xc2aNUuzZs1SS0uLHnroIcXjcX3yySf6wQ9+oNmzZ+vBBx/M6MQBAIXPOYTeeecdrVixIvXz5ddz1qxZo507d+rkyZPas2ePLly4oHg8rhUrVmjfvn2KRCKZmzUAYFIIBb5dLrMkkUgoGo2q+9wFVVW5NTAdGXO/KWUlhdG5aNijqWKub5vPHEs8GzEWedZNZuMezUg9+8B6N5D1aRhcUlwYj1H8TSKRUM1NUfX19V33eZx7FwBghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABgJuvfrJpLhdIR20ch3LZCmONkVgidxQuhI3YhdKyfTFg5AIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAICZvO2i/Yeufk2/6NYV+P/1JpzHeWDBLc41kjQeeJVpzLPwXzr7nGu+2jDTa6xxzzmOB+51z7f/q9dY//3euV51Pus/ODzmNVbYs7NyyLMZdk8i6VxTO7PCbzBP/YMjzjXh0uIszOTqfPax7+O6OMedz//cN+RcUxMtz8JM/oYjIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGbytoFpWUmRyhwbQH6pZobzOCHPbpEhjyaHkpxv02WxGdltIvj3ijybKn7UddG55juLb/UaK5dKPNfDdx19m1pOK3Nv9Bl47mPfx01l2P0p52Jy1GusIc/GszMqy5xrct2I1NeMaaXWU5iAIyEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJm87aJ90/SwIpGwU03fpZEszWYi3w7JvkqK8//vhZum53/3YZ/xguLcdsP2NTru3hHbtxu2r8ER987WkXK/p6liz9vm2zW9EIx57JFs1+T/MxsAYNIihAAAZpxCqLW1VYsXL1YkElF1dbUeeOABffjhh2nXCYJALS0tqq2tVUVFhZYvX65Tp05ldNIAgMnBKYTa29u1fv16HT16VG1tbRodHVVjY6MGBgZS13nuuee0bds27dixQ8eOHVMsFtN9992n/v7+jE8eAFDYnF7xe/3119N+3rVrl6qrq3X8+HHdfffdCoJA27dv15YtW7Rq1SpJ0u7du1VTU6O9e/fq8ccfz9zMAQAF74ZeE+rr65MkzZo1S5LU0dGh7u5uNTY2pq4TDod1zz336MiRI1f8HclkUolEIu0EAJgavEMoCAI1Nzfrzjvv1Pz58yVJ3d3dkqSampq069bU1KQu+7TW1lZFo9HUqa6uzndKAIAC4x1CGzZs0Hvvvadf/vKXEy779GcPgiC46ucRNm/erL6+vtSps7PTd0oAgALj9SmwjRs36rXXXtPhw4c1Z86c1PmxWEzSX4+I4vF46vyenp4JR0eXhcNhhcNuH0oFAEwOTkdCQRBow4YNevnll3Xw4EE1NDSkXd7Q0KBYLKa2trbUecPDw2pvb9eyZcsyM2MAwKThdCS0fv167d27V7/+9a8ViURSr/NEo1FVVFQoFApp06ZN2rp1q+bOnau5c+dq69atmjZtmh599NGs3AAAQOFyCqGdO3dKkpYvX552/q5du7R27VpJ0tNPP63BwUGtW7dO58+f15IlS/Tmm28qEolkZMIAgMnDKYSC4PpN6UKhkFpaWtTS0uI7JwDAFJG3XbSnhYtVGS52qylzu77k1yH2RnyWIL+SmdNKMzyTq/OeY6V7F+1xz7F8+dzfI2O+cxz3qhr1HG+2Y9d5Cz53d//QqNdYlWG/pzefDvm+jxnfpx/fRt/TPNbE57a5zI8GpgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMzkbQPTUCh01a8Ev5q+S8PO49yU86aPfp0Hzw+437aZJe4NRaWJX8/+2evca7r+fchrrFtmVXjVFXt0fqzwaIx7I0o8hxsdc2+YWlKc279DXZsSS/77MZd851ic45uWqz3ish4cCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzORtF+2i0F9PLirDeXtzblikfHLetpporruY57/x8cCrzqdDeK4VQkfsyawoD9efIyEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgJm8bc08OhZodMytm3BpyeTN1ELokOyjELoqB4FfV2vf21bkeV/7zjPf+d4u3+XwXf9c8t+TGZ5IBkzeZ20AQN4jhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJjJ2y7aRzv+XZXTR5xqkmNjzuM0frHGuUaSxsb9uti6dga/zKeqoqzYb6wcdo32XUffruI+43X2XvIaa86sCq+6dz4571X35boZzjXlnnvE1+Cw+2PUd4/47v/RsXGvOh8lxbk9DvB5jI57rL9LDUdCAAAzhBAAwIxTCLW2tmrx4sWKRCKqrq7WAw88oA8//DDtOmvXrlUoFEo7LV26NKOTBgBMDk4h1N7ervXr1+vo0aNqa2vT6OioGhsbNTAwkHa9+++/X11dXanTgQMHMjppAMDk4PTGhNdffz3t5127dqm6ulrHjx/X3XffnTo/HA4rFotlZoYAgEnrhl4T6uvrkyTNmjUr7fxDhw6purpat912mx577DH19PRc9Xckk0klEom0EwBgavAOoSAI1NzcrDvvvFPz589Pnd/U1KSXXnpJBw8e1PPPP69jx47p3nvvVTKZvOLvaW1tVTQaTZ3q6up8pwQAKDDenxPasGGD3nvvPb399ttp569evTr17/nz52vRokWqr6/X/v37tWrVqgm/Z/PmzWpubk79nEgkCCIAmCK8Qmjjxo167bXXdPjwYc2ZM+ea143H46qvr9fp06eveHk4HFY4HPaZBgCgwDmFUBAE2rhxo1555RUdOnRIDQ0N163p7e1VZ2en4vG49yQBAJOT02tC69ev1y9+8Qvt3btXkUhE3d3d6u7u1uDgoCTp4sWLeuqpp/S73/1On3zyiQ4dOqSVK1dq9uzZevDBB7NyAwAAhcvpSGjnzp2SpOXLl6edv2vXLq1du1bFxcU6efKk9uzZowsXLigej2vFihXat2+fIpFIxiYNAJgcQoFvt8osSSQSikaj+tOfz6uqqsqp9i/9V34H3rXUzvRrMplrA0OjzjWV5bntT+uzlS55NLSUpMpw7m6bb0NL3yarPk0mJb955rqBps8e8V0PXz4NO4s87+tc89kjPvs4kUgoNnuG+vr6rvs8Tu84AIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZnLb4fIzuNzgsL8/4Vzbf9G9gWmieMS5xsIljwamY8P538B00LOB6RgNTCeggWlm0MA0nc8+vvz8/Vnu77wLof7+fknSF/+h3ngmAIAb0d/fr2g0es3r5N1XOYyPj+vs2bOKRCIT/gJKJBKqq6tTZ2en89c8TFasSTrWYyLWJB3rMVGm1yQIAvX396u2tlZFRdc+2s67I6GioiLNmTPnmtepqqpi83wKa5KO9ZiINUnHekyUyTW53hHQZbwxAQBghhACAJgpqBAKh8N65plnFA6HraeSN1iTdKzHRKxJOtZjIss1ybs3JgAApo6COhICAEwuhBAAwAwhBAAwQwgBAMwUVAi98MILamhoUHl5uW6//Xb99re/tZ6SiZaWFoVCobRTLBaznlZOHT58WCtXrlRtba1CoZBeffXVtMuDIFBLS4tqa2tVUVGh5cuX69SpUzaTzYHrrcfatWsn7JmlS5faTDYHWltbtXjxYkUiEVVXV+uBBx7Qhx9+mHadqbZHPsuaWOyTggmhffv2adOmTdqyZYtOnDihu+66S01NTTpz5oz11EzMmzdPXV1dqdPJkyetp5RTAwMDWrhwoXbs2HHFy5977jlt27ZNO3bs0LFjxxSLxXTfffelehNONtdbD0m6//770/bMgQMHcjjD3Gpvb9f69et19OhRtbW1aXR0VI2NjRoYGEhdZ6rtkc+yJpLBPgkKxNe+9rXgiSeeSDvvC1/4QvD973/faEZ2nnnmmWDhwoXW08gbkoJXXnkl9fP4+HgQi8WCZ599NnXe0NBQEI1Gg5/85CcGM8ytT69HEATBmjVrgm9+85sm88kHPT09gaSgvb09CAL2SBBMXJMgsNknBXEkNDw8rOPHj6uxsTHt/MbGRh05csRoVrZOnz6t2tpaNTQ06OGHH9bHH39sPaW80dHRoe7u7rT9Eg6Hdc8990zZ/SJJhw4dUnV1tW677TY99thj6unpsZ5SzvT19UmSZs2aJYk9Ik1ck8tyvU8KIoTOnTunsbEx1dTUpJ1fU1Oj7u5uo1nZWbJkifbs2aM33nhDL774orq7u7Vs2TL19vZaTy0vXN4T7Je/aWpq0ksvvaSDBw/q+eef17Fjx3TvvfcqmXT/Dq5CEwSBmpubdeedd2r+/PmS2CNXWhPJZp/kXRfta/n0VzsEQZDzL7zKB01NTal/L1iwQHfccYc+//nPa/fu3WpubjacWX5hv/zN6tWrU/+eP3++Fi1apPr6eu3fv1+rVq0ynFn2bdiwQe+9957efvvtCZdN1T1ytTWx2CcFcSQ0e/ZsFRcXT/gLpaenZ8JfMlNRZWWlFixYoNOnT1tPJS9cfqcg++Xq4vG46uvrJ/2e2bhxo1577TW99dZbaV8RM5X3yNXW5EpysU8KIoTKysp0++23q62tLe38trY2LVu2zGhW+SOZTOqDDz5QPB63nkpeaGhoUCwWS9svw8PDam9vZ7/8h97eXnV2dk7aPRMEgTZs2KCXX35ZBw8eVENDQ9rlU3GPXG9NriQn+ySnb4O4Ab/61a+C0tLS4Gc/+1nw/vvvB5s2bQoqKyuDTz75xHpqOffkk08Ghw4dCj7++OPg6NGjwTe+8Y0gEolMqbXo7+8PTpw4EZw4cSKQFGzbti04ceJE8Mc//jEIgiB49tlng2g0Grz88svByZMng0ceeSSIx+NBIpEwnnl2XGs9+vv7gyeffDI4cuRI0NHREbz11lvBHXfcEdxyyy2Tdj2+973vBdFoNDh06FDQ1dWVOl26dCl1nam2R663Jlb7pGBCKAiC4Mc//nFQX18flJWVBV/96lfT3lo4laxevTqIx+NBaWlpUFtbG6xatSo4deqU9bRy6q233gokTTitWbMmCIK/vgX3mWeeCWKxWBAOh4O77747OHnypO2ks+ha63Hp0qWgsbExuPnmm4PS0tLg1ltvDdasWROcOXPGetpZc6W1kBTs2rUrdZ2ptkeutyZW+4SvcgAAmCmI14QAAJMTIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM/8ffiBR4gjQLhsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(N, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c4fa1",
   "metadata": {},
   "source": [
    "#### visualizing the count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c398942",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = np.empty_like(N, dtype=object)\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        annot[i,j] = f'{itos[i]}-{itos[j]}\\n{N[i,j]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60ac22c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m.DataFrame(N, index=stoi.keys(), columns=stoi.keys())\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m18\u001b[39m,\u001b[32m16\u001b[39m))\n\u001b[32m      4\u001b[39m sns.heatmap(df, annot=annot, fmt=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m, cbar=\u001b[38;5;28;01mTrue\u001b[39;00m, square=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(N, index=stoi.keys(), columns=stoi.keys())\n",
    "\n",
    "plt.figure(figsize=(18,16))\n",
    "sns.heatmap(df, annot=annot, fmt=\"\", cmap='Blues', cbar=True, square=True)\n",
    "\n",
    "# plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef32502",
   "metadata": {},
   "source": [
    "- In above image, a count means: 'a-.' = 6640\n",
    "- Shows, in out data, 6640 times a has been the last char\n",
    "\n",
    "#### Now we should figure out how to sample and generate from this matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088f436",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "- to sample we need some kind of **probability distribution**\n",
    "- we can convert these counts into prob distribution\n",
    "- by converting to proportions along a `row`\n",
    "- along a `row` - coz, at any instance we need to see what is the highest probability char to occur given current char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01da2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N / N.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e266081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441e760",
   "metadata": {},
   "source": [
    "- we can call this prob matrix as distribution learned by counting\n",
    "- now let's see how can we sample from the learned prob. matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7be9b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(P[0], 1, replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c6e67",
   "metadata": {},
   "source": [
    "- from prob distribution `P[0]`\n",
    "- num of indices will be sampled in the probabilities given by that tensor\n",
    "- If we sample enough times, we'll find that occurences are happening as per the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "087c4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze.\n",
      "momasurailezitynn.\n",
      "konimittain.\n",
      "llayn.\n",
      "ka.\n",
      "da.\n",
      "staiyaubrtthrigotai.\n",
      "moliellavo.\n",
      "ke.\n",
      "teda.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "    ix = 0\n",
    "    word = []\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, 1, replacement=True, generator=g).item()\n",
    "        word.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ff490",
   "metadata": {},
   "source": [
    "#### Are we doing any better than randomly sampling out of a uniform distribution for every current char\n",
    "- Means, prob distribution is uniform\n",
    "- 1./27 for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5495746b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexzm.\n",
      "zoglkurkicqzktyhwmvmzimjttainrlkfukzkktda.\n",
      "sfcxvpubjtbhrmgotzx.\n",
      "iczixqctvujkwptedogkkjemkmmsidguenkbvgynywftbspmhwcivgbvtahlvsu.\n",
      "dsdxxblnwglhpyiw.\n",
      "igwnjwrpfdwipkwzkm.\n",
      "desu.\n",
      "firmt.\n",
      "gbiksjbquabsvoth.\n",
      "kuysxqevhcmrbxmcwyhrrjenvxmvpfkmwmghfvjzxobomysox.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for _ in range(10):\n",
    "    ix = 0\n",
    "    word = []\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        p = torch.ones(27) / 27\n",
    "        ix = torch.multinomial(p, 1, replacement=True, generator=g).item()\n",
    "        word.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76a630",
   "metadata": {},
   "source": [
    "### I think our count based sampling method, is somewhat better than the random baseline generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f527c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db2b48a",
   "metadata": {},
   "source": [
    "## Evaluating performance - Summarize QUALITY of the model in SINGLE NUMBER\n",
    "- maximising likelihood of the dataset\n",
    "- maximizing product of all bigram probabilities -> also called **likelihood**\n",
    "- maximizing sum of log of all bigram probabilities -> **log-likelihood**\n",
    "- coz, all probs are b/w 0-1, logs are negative numbers, therefore, the sum of all is also negative\n",
    "- Therefore, we MINIMIZE **negative log-likelihood**\n",
    "\n",
    "## Maximizing likelihood == Minimizing negative log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95ea0313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-likelihood = -559891.75\n",
      "Negative log-likelihood = 2.45409\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0\n",
    "n = 0 # used to normalize the nll\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.']+list(w)+['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "        n += 1\n",
    "        prob = P[ix1,ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        # print(f'{ch1}{ch2}:: prob = {prob:.5f} | log-prob = {logprob:.5f}')\n",
    "        log_likelihood += logprob\n",
    "\n",
    "nll = - log_likelihood / n\n",
    "print(f'log-likelihood = {log_likelihood}')\n",
    "print(f'Negative log-likelihood = {nll:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54efbbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll=tensor(inf)\n"
     ]
    }
   ],
   "source": [
    "# calculating likelihood of a word\n",
    "n=0\n",
    "log_likelihood = 0\n",
    "\n",
    "chs = ['.'] + list('mrigankq') + ['.']\n",
    "for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1, ix2 = stoi[ch1], stoi[ch2]\n",
    "    n += 1\n",
    "    prob = P[ix1,ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    # print(f'{ch1}{ch2}:: prob = {prob:.5f} | log-prob = {logprob:.5f}')\n",
    "    log_likelihood += logprob\n",
    "nll = -log_likelihood / n\n",
    "print(f'{nll=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67b535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
