{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6fc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fba2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('../gpt/input.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7eeb1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(''.join(text))))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "stoi = {ch:i for i,ch in enumerate(vocab)}\n",
    "itos = {i:ch for ch,i in stoi.items()}\n",
    "\n",
    "encode = lambda text: [stoi[ch] for ch in text]\n",
    "decode = lambda tokens: ''.join([itos[token] for token in tokens])\n",
    "\n",
    "data = encode(text)\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c419616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "block_size = 100\n",
    "\n",
    "def get_batch(split):\n",
    "    split_data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(split_data)-block_size, (batch_size,))\n",
    "    x = [split_data[i : i + block_size] for i in ix]\n",
    "    y = [split_data[i+1 : i + block_size + 1] for i in ix]\n",
    "    return torch.tensor(x), torch.tensor(y)\n",
    "x,y = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b01e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 100]), torch.Size([100, 100]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b10027a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlstm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiLayerLSTM\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:471\u001b[39m, in \u001b[36m_lock_unlock_module\u001b[39m\u001b[34m(name)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:365\u001b[39m, in \u001b[36macquire\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from lstm import MultiLayerLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654cf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
